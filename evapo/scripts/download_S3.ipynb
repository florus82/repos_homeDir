{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "connection = openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SENTINEL3_OLCI_L1B',\n",
       " 'SENTINEL3_SLSTR',\n",
       " 'SENTINEL_5P_L2',\n",
       " 'COPERNICUS_VEGETATION_PHENOLOGY_PRODUCTIVITY_10M_SEASON1',\n",
       " 'COPERNICUS_VEGETATION_PHENOLOGY_PRODUCTIVITY_10M_SEASON2',\n",
       " 'COPERNICUS_PLANT_PHENOLOGY_INDEX',\n",
       " 'ESA_WORLDCOVER_10M_2020_V1',\n",
       " 'ESA_WORLDCOVER_10M_2021_V2',\n",
       " 'COPERNICUS_VEGETATION_INDICES',\n",
       " 'SENTINEL2_L1C',\n",
       " 'SENTINEL2_L2A',\n",
       " 'SENTINEL1_GRD',\n",
       " 'COPERNICUS_30',\n",
       " 'LANDSAT8_L2',\n",
       " 'SENTINEL3_SYN_L2_SYN',\n",
       " 'SENTINEL3_SLSTR_L2_LST',\n",
       " 'SENTINEL1_GLOBAL_MOSAICS']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.list_collection_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "    if (!window.customElements || !window.customElements.get('openeo-collection')) {\n",
       "        var el = document.createElement('script');\n",
       "        el.src = \"https://cdn.jsdelivr.net/npm/@openeo/vue-components@2/assets/openeo.min.js\";\n",
       "        document.head.appendChild(el);\n",
       "\n",
       "        var font = document.createElement('font');\n",
       "        font.as = \"font\";\n",
       "        font.type = \"font/woff2\";\n",
       "        font.crossOrigin = true;\n",
       "        font.href = \"https://use.fontawesome.com/releases/v5.13.0/webfonts/fa-solid-900.woff2\"\n",
       "        document.head.appendChild(font);\n",
       "    }\n",
       "    </script>\n",
       "    <openeo-collection>\n",
       "        <script type=\"application/json\">{\"mapOptions\": {}, \"data\": {\"cube:dimensions\": {\"bands\": {\"type\": \"bands\", \"values\": [\"LST\", \"LST_uncertainty\", \"exception\", \"confidence_in\", \"sunAzimuthAngles\", \"sunZenithAngles\", \"viewAzimuthAngles\", \"viewZenithAngles\"]}, \"t\": {\"extent\": [\"2016-04-17T11:33:13Z\", null], \"step\": \"P2D\", \"type\": \"temporal\"}, \"x\": {\"axis\": \"x\", \"extent\": [-180, 180], \"reference_system\": 4326, \"step\": 0.008928571428571, \"type\": \"spatial\"}, \"y\": {\"axis\": \"y\", \"extent\": [-90, 90], \"reference_system\": 4326, \"step\": 0.008928571428571, \"type\": \"spatial\"}}, \"description\": \"*Experimental* Daily global Sentinel-3 land surface temperature at 1km resolution. Land surface temperature is defined as the effective radiometric temperature of the Earth's surface \\\"skin\\\" in the instrument field of view. Here, \\\"skin\\\" is referring to the top surface in bare soil conditions and to the effective emitting temperature of vegetation \\\"canopies\\\" as determined from a view of the top of a canopy.\\n This product is derived from the SLSTR (Sea and Land Surface Temperature Radiometer) instrument on board the Sentinel-3 satellite.\\n\\n Multiple observations may be available per day, we recommend temporal aggregation to create daily composites. \", \"experimental\": true, \"extent\": {\"spatial\": {\"bbox\": [[-180, -90, 180, 90]]}, \"temporal\": {\"interval\": [[\"2016-04-17T11:33:13Z\", null]]}}, \"id\": \"SENTINEL3_SLSTR_L2_LST\", \"keywords\": [\"COPERNICUS\", \"ESA\", \"Sentinel-3\", \"SLSTR\"], \"license\": \"proprietary\", \"links\": [{\"href\": \"https://sentinels.copernicus.eu/documents/247904/690755/Sentinel_Data_Legal_Notice\", \"rel\": \"license\", \"type\": \"application/pdf\"}, {\"href\": \"https://documentation.dataspace.copernicus.eu/Data/SentinelMissions/Sentinel3.html#sentinel-3-slstr-level-2\", \"rel\": \"alternate\", \"title\": \"Data space collection documentation\", \"type\": \"application/html\"}, {\"href\": \"https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-3-slstr/processing-levels/level-2\", \"rel\": \"about\", \"title\": \"User guide\"}, {\"href\": \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel3/search.json?productType=SL_2_LST___\", \"rel\": \"opensearch\", \"title\": \"Catalog API\"}, {\"href\": \"https://sentinel.esa.int/documents/247904/4598082/Sentinel-3-SLSTR-Land-Handbook.pdf\", \"rel\": \"about\", \"title\": \"Handbook\", \"type\": \"application/pdf\"}, {\"href\": \"https://github.com/Open-EO/openeo-community-examples/blob/main/python/Heatwave/HeatwaveNL.ipynb\", \"rel\": \"example\", \"title\": \"Heatwave example\"}, {\"href\": \"https://openeo.dataspace.copernicus.eu/openeo/1.2/collections\", \"rel\": \"root\"}, {\"href\": \"https://openeo.dataspace.copernicus.eu/openeo/1.2/collections\", \"rel\": \"parent\"}, {\"href\": \"https://openeo.dataspace.copernicus.eu/openeo/1.2/collections/SENTINEL3_SLSTR_L2_LST\", \"rel\": \"self\"}], \"providers\": [{\"name\": \"ESA\", \"roles\": [\"producer\"], \"url\": \"https://esa.int/\"}, {\"name\": \"CDSE\", \"roles\": [\"processor\", \"host\"], \"url\": \"https://dataspace.copernicus.eu/\"}], \"stac_extensions\": [\"https://stac-extensions.github.io/datacube/v2.2.0/schema.json\", \"https://stac-extensions.github.io/eo/v1.1.0/schema.json\"], \"stac_version\": \"0.9.0\", \"summaries\": {\"eo:bands\": [{\"aliases\": [\"LST_in:LST\"], \"common_name\": \"surface_temperature\", \"gsd\": 1000, \"name\": \"LST\", \"offset\": 290, \"scale\": 0.0020000001, \"unit\": \"K\"}, {\"aliases\": [\"LST_in:LST_uncertainty\"], \"common_name\": \"surface_temperature_standard_error\", \"gsd\": 1000, \"name\": \"LST_uncertainty\", \"offset\": 0, \"scale\": 0.0020000001, \"unit\": \"K\"}, {\"aliases\": [\"LST_in:exception\"], \"gsd\": 1000, \"name\": \"exception\", \"offset\": 0, \"scale\": 1}, {\"aliases\": [\"flags_in:confidence_in\"], \"description\": \"quality control flags including summary_cloud flag\", \"gsd\": 1000, \"name\": \"confidence_in\"}, {\"aliases\": [\"geometry_tn:solar_azimuth_tn\"], \"description\": \"nadir view solar azimuth angles\", \"gsd\": 1000, \"name\": \"sunAzimuthAngles\", \"unit\": \"deg\"}, {\"aliases\": [\"geometry_tn:solar_zenith_tn\"], \"description\": \"nadir view solar zenith angles\", \"gsd\": 1000, \"name\": \"sunZenithAngles\", \"unit\": \"deg\"}, {\"aliases\": [\"geometry_tn:sat_azimuth_tn\"], \"description\": \"nadir view satellite azimuth angles\", \"gsd\": 1000, \"name\": \"viewAzimuthAngles\", \"unit\": \"deg\"}, {\"aliases\": [\"geometry_tn:sat_zenith_tn\"], \"description\": \"nadir view satellite zenith angles\", \"gsd\": 1000, \"name\": \"viewZenithAngles\", \"unit\": \"deg\"}], \"raster:bands\": [{}, {}, {\"classification:bitfields\": [{\"classes\": [{\"name\": \"not_absent\", \"value\": 0}, {\"name\": \"absent\", \"value\": 1}], \"description\": \"ISP absent\", \"length\": 1, \"name\": \"ISP_absent\", \"offset\": 0}, {\"classes\": [{\"name\": \"not_absent\", \"value\": 0}, {\"name\": \"absent\", \"value\": 1}], \"description\": \"Pixel absent\", \"length\": 1, \"name\": \"Pixel_absent\", \"offset\": 1}, {\"classes\": [{\"name\": \"decompressed\", \"value\": 0}, {\"name\": \"not_decompressed\", \"value\": 1}], \"description\": \"Not decompressed\", \"length\": 1, \"name\": \"Not_decompressed\", \"offset\": 2}, {\"classes\": [{\"name\": \"signal\", \"value\": 0}, {\"name\": \"no_signal\", \"value\": 1}], \"description\": \"No signal in channel\", \"length\": 1, \"name\": \"No_signal\", \"offset\": 3}, {\"classes\": [{\"name\": \"no_saturation\", \"value\": 0}, {\"name\": \"saturated\", \"value\": 1}], \"description\": \"Saturation in channel\", \"length\": 1, \"name\": \"Saturation\", \"offset\": 4}, {\"classes\": [{\"name\": \"not_invalid\", \"value\": 0}, {\"name\": \"invalid\", \"value\": 1}], \"description\": \"Derived radiance outside calibration\", \"length\": 1, \"name\": \"Invalid_radiance\", \"offset\": 5}, {\"classes\": [{\"name\": \"parameters_available\", \"value\": 0}, {\"name\": \"parameters_unavailable\", \"value\": 1}], \"description\": \"Calibration parameters unavailable\", \"length\": 1, \"name\": \"No_parameters\", \"offset\": 6}, {\"classes\": [{\"name\": \"not_unfilled\", \"value\": 0}, {\"name\": \"unfilled\", \"value\": 1}], \"description\": \"Unfilled pixe\", \"length\": 1, \"name\": \"Unfilled_pixel\", \"offset\": 7}, {\"classes\": [{\"name\": \"no_underflow\", \"value\": 0}, {\"name\": \"underflow\", \"value\": 1}], \"description\": \"LST underflow\", \"length\": 1, \"name\": \"LST_underflow\", \"offset\": 8}, {\"classes\": [{\"name\": \"no_overflow\", \"value\": 0}, {\"name\": \"overflow\", \"value\": 1}], \"description\": \"LST overflow\", \"length\": 1, \"name\": \"LST_overflow\", \"offset\": 9}, {\"classes\": [{\"name\": \"no\", \"value\": 0}, {\"name\": \"yes\", \"value\": 1}], \"description\": \"LST could not be calculated for this biome type\", \"length\": 1, \"name\": \"biome\", \"offset\": 10}]}, {}, {}, {}, {}, {}]}, \"title\": \"Daily global Sentinel-3 Land surface temperature at 1km resolution\"}}</script>\n",
       "    </openeo-collection>\n",
       "    "
      ],
      "text/plain": [
       "{'cube:dimensions': {'bands': {'type': 'bands',\n",
       "   'values': ['LST',\n",
       "    'LST_uncertainty',\n",
       "    'exception',\n",
       "    'confidence_in',\n",
       "    'sunAzimuthAngles',\n",
       "    'sunZenithAngles',\n",
       "    'viewAzimuthAngles',\n",
       "    'viewZenithAngles']},\n",
       "  't': {'extent': ['2016-04-17T11:33:13Z', None],\n",
       "   'step': 'P2D',\n",
       "   'type': 'temporal'},\n",
       "  'x': {'axis': 'x',\n",
       "   'extent': [-180, 180],\n",
       "   'reference_system': 4326,\n",
       "   'step': 0.008928571428571,\n",
       "   'type': 'spatial'},\n",
       "  'y': {'axis': 'y',\n",
       "   'extent': [-90, 90],\n",
       "   'reference_system': 4326,\n",
       "   'step': 0.008928571428571,\n",
       "   'type': 'spatial'}},\n",
       " 'description': '*Experimental* Daily global Sentinel-3 land surface temperature at 1km resolution. Land surface temperature is defined as the effective radiometric temperature of the Earth\\'s surface \"skin\" in the instrument field of view. Here, \"skin\" is referring to the top surface in bare soil conditions and to the effective emitting temperature of vegetation \"canopies\" as determined from a view of the top of a canopy.\\n This product is derived from the SLSTR (Sea and Land Surface Temperature Radiometer) instrument on board the Sentinel-3 satellite.\\n\\n Multiple observations may be available per day, we recommend temporal aggregation to create daily composites. ',\n",
       " 'experimental': True,\n",
       " 'extent': {'spatial': {'bbox': [[-180, -90, 180, 90]]},\n",
       "  'temporal': {'interval': [['2016-04-17T11:33:13Z', None]]}},\n",
       " 'id': 'SENTINEL3_SLSTR_L2_LST',\n",
       " 'keywords': ['COPERNICUS', 'ESA', 'Sentinel-3', 'SLSTR'],\n",
       " 'license': 'proprietary',\n",
       " 'links': [{'href': 'https://sentinels.copernicus.eu/documents/247904/690755/Sentinel_Data_Legal_Notice',\n",
       "   'rel': 'license',\n",
       "   'type': 'application/pdf'},\n",
       "  {'href': 'https://documentation.dataspace.copernicus.eu/Data/SentinelMissions/Sentinel3.html#sentinel-3-slstr-level-2',\n",
       "   'rel': 'alternate',\n",
       "   'title': 'Data space collection documentation',\n",
       "   'type': 'application/html'},\n",
       "  {'href': 'https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-3-slstr/processing-levels/level-2',\n",
       "   'rel': 'about',\n",
       "   'title': 'User guide'},\n",
       "  {'href': 'https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel3/search.json?productType=SL_2_LST___',\n",
       "   'rel': 'opensearch',\n",
       "   'title': 'Catalog API'},\n",
       "  {'href': 'https://sentinel.esa.int/documents/247904/4598082/Sentinel-3-SLSTR-Land-Handbook.pdf',\n",
       "   'rel': 'about',\n",
       "   'title': 'Handbook',\n",
       "   'type': 'application/pdf'},\n",
       "  {'href': 'https://github.com/Open-EO/openeo-community-examples/blob/main/python/Heatwave/HeatwaveNL.ipynb',\n",
       "   'rel': 'example',\n",
       "   'title': 'Heatwave example'},\n",
       "  {'href': 'https://openeo.dataspace.copernicus.eu/openeo/1.2/collections',\n",
       "   'rel': 'root'},\n",
       "  {'href': 'https://openeo.dataspace.copernicus.eu/openeo/1.2/collections',\n",
       "   'rel': 'parent'},\n",
       "  {'href': 'https://openeo.dataspace.copernicus.eu/openeo/1.2/collections/SENTINEL3_SLSTR_L2_LST',\n",
       "   'rel': 'self'}],\n",
       " 'providers': [{'name': 'ESA',\n",
       "   'roles': ['producer'],\n",
       "   'url': 'https://esa.int/'},\n",
       "  {'name': 'CDSE',\n",
       "   'roles': ['processor', 'host'],\n",
       "   'url': 'https://dataspace.copernicus.eu/'}],\n",
       " 'stac_extensions': ['https://stac-extensions.github.io/datacube/v2.2.0/schema.json',\n",
       "  'https://stac-extensions.github.io/eo/v1.1.0/schema.json'],\n",
       " 'stac_version': '0.9.0',\n",
       " 'summaries': {'eo:bands': [{'aliases': ['LST_in:LST'],\n",
       "    'common_name': 'surface_temperature',\n",
       "    'gsd': 1000,\n",
       "    'name': 'LST',\n",
       "    'offset': 290,\n",
       "    'scale': 0.0020000001,\n",
       "    'unit': 'K'},\n",
       "   {'aliases': ['LST_in:LST_uncertainty'],\n",
       "    'common_name': 'surface_temperature_standard_error',\n",
       "    'gsd': 1000,\n",
       "    'name': 'LST_uncertainty',\n",
       "    'offset': 0,\n",
       "    'scale': 0.0020000001,\n",
       "    'unit': 'K'},\n",
       "   {'aliases': ['LST_in:exception'],\n",
       "    'gsd': 1000,\n",
       "    'name': 'exception',\n",
       "    'offset': 0,\n",
       "    'scale': 1},\n",
       "   {'aliases': ['flags_in:confidence_in'],\n",
       "    'description': 'quality control flags including summary_cloud flag',\n",
       "    'gsd': 1000,\n",
       "    'name': 'confidence_in'},\n",
       "   {'aliases': ['geometry_tn:solar_azimuth_tn'],\n",
       "    'description': 'nadir view solar azimuth angles',\n",
       "    'gsd': 1000,\n",
       "    'name': 'sunAzimuthAngles',\n",
       "    'unit': 'deg'},\n",
       "   {'aliases': ['geometry_tn:solar_zenith_tn'],\n",
       "    'description': 'nadir view solar zenith angles',\n",
       "    'gsd': 1000,\n",
       "    'name': 'sunZenithAngles',\n",
       "    'unit': 'deg'},\n",
       "   {'aliases': ['geometry_tn:sat_azimuth_tn'],\n",
       "    'description': 'nadir view satellite azimuth angles',\n",
       "    'gsd': 1000,\n",
       "    'name': 'viewAzimuthAngles',\n",
       "    'unit': 'deg'},\n",
       "   {'aliases': ['geometry_tn:sat_zenith_tn'],\n",
       "    'description': 'nadir view satellite zenith angles',\n",
       "    'gsd': 1000,\n",
       "    'name': 'viewZenithAngles',\n",
       "    'unit': 'deg'}],\n",
       "  'raster:bands': [{},\n",
       "   {},\n",
       "   {'classification:bitfields': [{'classes': [{'name': 'not_absent',\n",
       "        'value': 0},\n",
       "       {'name': 'absent', 'value': 1}],\n",
       "      'description': 'ISP absent',\n",
       "      'length': 1,\n",
       "      'name': 'ISP_absent',\n",
       "      'offset': 0},\n",
       "     {'classes': [{'name': 'not_absent', 'value': 0},\n",
       "       {'name': 'absent', 'value': 1}],\n",
       "      'description': 'Pixel absent',\n",
       "      'length': 1,\n",
       "      'name': 'Pixel_absent',\n",
       "      'offset': 1},\n",
       "     {'classes': [{'name': 'decompressed', 'value': 0},\n",
       "       {'name': 'not_decompressed', 'value': 1}],\n",
       "      'description': 'Not decompressed',\n",
       "      'length': 1,\n",
       "      'name': 'Not_decompressed',\n",
       "      'offset': 2},\n",
       "     {'classes': [{'name': 'signal', 'value': 0},\n",
       "       {'name': 'no_signal', 'value': 1}],\n",
       "      'description': 'No signal in channel',\n",
       "      'length': 1,\n",
       "      'name': 'No_signal',\n",
       "      'offset': 3},\n",
       "     {'classes': [{'name': 'no_saturation', 'value': 0},\n",
       "       {'name': 'saturated', 'value': 1}],\n",
       "      'description': 'Saturation in channel',\n",
       "      'length': 1,\n",
       "      'name': 'Saturation',\n",
       "      'offset': 4},\n",
       "     {'classes': [{'name': 'not_invalid', 'value': 0},\n",
       "       {'name': 'invalid', 'value': 1}],\n",
       "      'description': 'Derived radiance outside calibration',\n",
       "      'length': 1,\n",
       "      'name': 'Invalid_radiance',\n",
       "      'offset': 5},\n",
       "     {'classes': [{'name': 'parameters_available', 'value': 0},\n",
       "       {'name': 'parameters_unavailable', 'value': 1}],\n",
       "      'description': 'Calibration parameters unavailable',\n",
       "      'length': 1,\n",
       "      'name': 'No_parameters',\n",
       "      'offset': 6},\n",
       "     {'classes': [{'name': 'not_unfilled', 'value': 0},\n",
       "       {'name': 'unfilled', 'value': 1}],\n",
       "      'description': 'Unfilled pixe',\n",
       "      'length': 1,\n",
       "      'name': 'Unfilled_pixel',\n",
       "      'offset': 7},\n",
       "     {'classes': [{'name': 'no_underflow', 'value': 0},\n",
       "       {'name': 'underflow', 'value': 1}],\n",
       "      'description': 'LST underflow',\n",
       "      'length': 1,\n",
       "      'name': 'LST_underflow',\n",
       "      'offset': 8},\n",
       "     {'classes': [{'name': 'no_overflow', 'value': 0},\n",
       "       {'name': 'overflow', 'value': 1}],\n",
       "      'description': 'LST overflow',\n",
       "      'length': 1,\n",
       "      'name': 'LST_overflow',\n",
       "      'offset': 9},\n",
       "     {'classes': [{'name': 'no', 'value': 0}, {'name': 'yes', 'value': 1}],\n",
       "      'description': 'LST could not be calculated for this biome type',\n",
       "      'length': 1,\n",
       "      'name': 'biome',\n",
       "      'offset': 10}]},\n",
       "   {},\n",
       "   {},\n",
       "   {},\n",
       "   {},\n",
       "   {}]},\n",
       " 'title': 'Daily global Sentinel-3 Land surface temperature at 1km resolution'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.describe_collection(\"SENTINEL3_SLSTR_L2_LST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/data/Aldhani/eoagritwin/et/data/stations/ICOS_stations.geojson') as f:\n",
    "    d = json.load(f)\n",
    "\n",
    "posL = [feature['properties']['Position'].split(' ') for feature in d['features']]\n",
    "datL = [feature['properties']['labelingDate'].split('-') for feature in d['features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.51259 50.95004\n",
      "['2020-01-01', '2020-03-01']\n",
      "{'west': 10.84, 'south': 41.7, 'east': 11, 'north': 42.05}\n"
     ]
    }
   ],
   "source": [
    "X, Y = float(posL[0][0]), float(posL[0][1])\n",
    "print(X,Y)\n",
    "dat = [int(dat) for dat in datL[0]]\n",
    "\n",
    "date = [\"-\".join(map(str, [dat[0], dat[1]-1, dat[2]])), \"-\".join(map(str, [dat[0], dat[1], dat[2]]))]\n",
    "aoi = {\"west\": X - 0.1, \"south\": Y - .1, \"east\": X + .1, \"north\": Y + .1}\n",
    "\n",
    "date = ['2020-01-01', '2020-03-01']\n",
    "aoi = {\"west\": 10.84, \"south\": 41.7, \"east\": 11, \"north\": 42.05}\n",
    "print(date)\n",
    "print(aoi)\n",
    "\n",
    "sentinel3_cube = connection.load_collection(\n",
    "    \"SENTINEL3_SLSTR_L2_LST\",\n",
    "    spatial_extent = aoi,\n",
    "    temporal_extent = date,\n",
    "    bands=[\"LST\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_mask = connection.load_collection(\n",
    "    \"SENTINEL3_SLSTR_L2_LST\",\n",
    "    temporal_extent = date,\n",
    "    spatial_extent = aoi,\n",
    "    bands=[\"confidence_in\"],\n",
    ")\n",
    "\n",
    "cloud_mask = cloud_mask >= 16384\n",
    "\n",
    "LST = sentinel3_cube.mask(cloud_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenEoApiError",
     "evalue": "[500] Internal: Server error: Exception during Spark execution: java.io.EOFException (ref: r-250221145628493fb4524e933d99d6f0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenEoApiError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mLST\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLST-1.nc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#sentinel3_cube.download('S3test.nc')\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/evapo_sentinelhub/lib/python3.13/site-packages/openeo/rest/datacube.py:2267\u001b[0m, in \u001b[0;36mDataCube.download\u001b[0;34m(self, outputfile, format, options, validate, auto_add_save_result)\u001b[0m\n\u001b[1;32m   2258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_add_save_result:\n\u001b[1;32m   2259\u001b[0m     cube \u001b[38;5;241m=\u001b[39m _ensure_save_result(\n\u001b[1;32m   2260\u001b[0m         cube\u001b[38;5;241m=\u001b[39mcube,\n\u001b[1;32m   2261\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2265\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataCube.download()\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2266\u001b[0m     )\n\u001b[0;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcube\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/evapo_sentinelhub/lib/python3.13/site-packages/openeo/rest/connection.py:1681\u001b[0m, in \u001b[0;36mConnection.download\u001b[0;34m(self, graph, outputfile, timeout, validate, chunk_size)\u001b[0m\n\u001b[1;32m   1679\u001b[0m pg_with_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_with_process_graph(process_graph\u001b[38;5;241m=\u001b[39mgraph)\n\u001b[1;32m   1680\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preflight_validation(pg_with_metadata\u001b[38;5;241m=\u001b[39mpg_with_metadata, validate\u001b[38;5;241m=\u001b[39mvalidate)\n\u001b[0;32m-> 1681\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/result\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpg_with_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDEFAULT_TIMEOUT_SYNCHRONOUS_EXECUTE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputfile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Path(outputfile)\u001b[38;5;241m.\u001b[39mopen(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/mambaforge/envs/evapo_sentinelhub/lib/python3.13/site-packages/openeo/rest/connection.py:248\u001b[0m, in \u001b[0;36mRestApiConnection.post\u001b[0;34m(self, path, json, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m, json: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    Do POST request to REST API.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    :return: response: Response\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/evapo_sentinelhub/lib/python3.13/site-packages/openeo/rest/connection.py:830\u001b[0m, in \u001b[0;36mConnection.request\u001b[0;34m(self, method, path, headers, auth, check_error, expected_status, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(Connection, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    824\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod, path\u001b[38;5;241m=\u001b[39mpath, headers\u001b[38;5;241m=\u001b[39mheaders, auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m    825\u001b[0m         check_error\u001b[38;5;241m=\u001b[39mcheck_error, expected_status\u001b[38;5;241m=\u001b[39mexpected_status, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    826\u001b[0m     )\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;66;03m# Initial request attempt\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OpenEoApiError \u001b[38;5;28;01mas\u001b[39;00m api_exc:\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m api_exc\u001b[38;5;241m.\u001b[39mhttp_status_code \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m401\u001b[39m, \u001b[38;5;241m403\u001b[39m} \u001b[38;5;129;01mand\u001b[39;00m api_exc\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenInvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;66;03m# Auth token expired: can we refresh?\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/evapo_sentinelhub/lib/python3.13/site-packages/openeo/rest/connection.py:823\u001b[0m, in \u001b[0;36mConnection.request.<locals>._request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_request\u001b[39m():\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_status\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/evapo_sentinelhub/lib/python3.13/site-packages/openeo/rest/connection.py:186\u001b[0m, in \u001b[0;36mRestApiConnection.request\u001b[0;34m(self, method, path, headers, auth, check_error, expected_status, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m expected_status \u001b[38;5;241m=\u001b[39m ensure_list(expected_status) \u001b[38;5;28;01mif\u001b[39;00m expected_status \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_error \u001b[38;5;129;01mand\u001b[39;00m status \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m expected_status:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_api_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expected_status \u001b[38;5;129;01mand\u001b[39;00m status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m expected_status:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenEoRestError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot status code \u001b[39m\u001b[38;5;132;01m{s!r}\u001b[39;00m\u001b[38;5;124m for `\u001b[39m\u001b[38;5;132;01m{m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{p}\u001b[39;00m\u001b[38;5;124m` (expected \u001b[39m\u001b[38;5;132;01m{e!r}\u001b[39;00m\u001b[38;5;124m) with body \u001b[39m\u001b[38;5;132;01m{body}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    189\u001b[0m         m\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(), p\u001b[38;5;241m=\u001b[39mpath, s\u001b[38;5;241m=\u001b[39mstatus, e\u001b[38;5;241m=\u001b[39mexpected_status, body\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    190\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/evapo_sentinelhub/lib/python3.13/site-packages/openeo/rest/connection.py:206\u001b[0m, in \u001b[0;36mRestApiConnection._raise_api_error\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    204\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_code \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error_code, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m error_message \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error_message, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m OpenEoApiError(\n\u001b[1;32m    207\u001b[0m             http_status_code\u001b[38;5;241m=\u001b[39mstatus_code,\n\u001b[1;32m    208\u001b[0m             code\u001b[38;5;241m=\u001b[39merror_code,\n\u001b[1;32m    209\u001b[0m             message\u001b[38;5;241m=\u001b[39merror_message,\n\u001b[1;32m    210\u001b[0m             \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    211\u001b[0m             url\u001b[38;5;241m=\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# Failed to parse it as a compliant openEO API error: show body as-is in the exception.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[0;31mOpenEoApiError\u001b[0m: [500] Internal: Server error: Exception during Spark execution: java.io.EOFException (ref: r-250221145628493fb4524e933d99d6f0)"
     ]
    }
   ],
   "source": [
    "LST.download(\"LST-1.nc\")\n",
    "#sentinel3_cube.download('S3test.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.load_dataset(\"LST-1.nc\")\n",
    "ds[\"LST\"].plot.imshow(col=\"t\", col_wrap=2, vmin=200, vmax=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"LST_celsius\"] = ds[\"LST\"] - 273.15\n",
    "\n",
    "# Plot the LST in Celsius with a rainbow colormap\n",
    "img_c = ds[\"LST_celsius\"].plot.imshow(col=\"t\", col_wrap=4, vmin=-10, vmax=45, cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = sentinel3_cube.create_job(out_format=\"GTiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#job.start_and_wait()\n",
    "#job.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-2502211459014f79a2b2228051b21290': send 'start'\n",
      "0:00:14 Job 'j-2502211459014f79a2b2228051b21290': created (progress 0%)\n",
      "0:00:19 Job 'j-2502211459014f79a2b2228051b21290': created (progress 0%)\n",
      "0:00:26 Job 'j-2502211459014f79a2b2228051b21290': created (progress 0%)\n",
      "0:00:34 Job 'j-2502211459014f79a2b2228051b21290': created (progress 0%)\n",
      "0:00:44 Job 'j-2502211459014f79a2b2228051b21290': created (progress 0%)\n",
      "0:00:56 Job 'j-2502211459014f79a2b2228051b21290': created (progress 0%)\n",
      "0:01:12 Job 'j-2502211459014f79a2b2228051b21290': running (progress N/A)\n",
      "0:01:32 Job 'j-2502211459014f79a2b2228051b21290': running (progress N/A)\n",
      "0:01:56 Job 'j-2502211459014f79a2b2228051b21290': running (progress N/A)\n",
      "0:02:26 Job 'j-2502211459014f79a2b2228051b21290': running (progress N/A)\n",
      "0:03:04 Job 'j-2502211459014f79a2b2228051b21290': running (progress N/A)\n",
      "0:03:50 Job 'j-2502211459014f79a2b2228051b21290': error (progress N/A)\n",
      "Your batch job 'j-2502211459014f79a2b2228051b21290' failed. Error logs:\n",
      "[{'id': '[1740150043244, 800627]', 'time': '2025-02-21T15:00:43.244Z', 'level': 'error', 'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 10.84, 'xmax': 11.982857142857087, 'ymin': 40.90714285714291, 'ymax': 42.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\"}, {'id': '[1740150050157, 313277]', 'time': '2025-02-21T15:00:50.157Z', 'level': 'error', 'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {'xmin': 10.84, 'xmax': 11.982857142857087, 'ymin': 40.90714285714291, 'ymax': 42.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\"}, {'id': '[1740150051208, 695548]', 'time': '2025-02-21T15:00:51.208Z', 'level': 'error', 'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 10.84, 'xmax': 11.982857142857087, 'ymin': 40.90714285714291, 'ymax': 42.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"}, {'id': '[1740150052805, 652402]', 'time': '2025-02-21T15:00:52.805Z', 'level': 'error', 'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 10.84, 'xmax': 11.982857142857087, 'ymin': 40.90714285714291, 'ymax': 42.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\"}, {'id': '[1740150053118, 981724]', 'time': '2025-02-21T15:00:53.118Z', 'level': 'error', 'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {'xmin': 10.84, 'xmax': 11.982857142857087, 'ymin': 40.90714285714291, 'ymax': 42.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\"}, {'id': '[1740150057271, 899828]', 'time': '2025-02-21T15:00:57.271Z', 'level': 'error', 'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 10.84, 'xmax': 11.982857142857087, 'ymin': 40.90714285714291, 'ymax': 42.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\"}, {'id': '[1740150057396, 3321]', 'time': '2025-02-21T15:00:57.396Z', 'level': 'error', 'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/15/S3A_SL_2_LST____20200115T085458_20200115T103557_20200116T153245_6059_053_378______LN2_O_NT_004.SEN3 and extent {'xmin': 10.84, 'xmax': 11.982857142857087, 'ymin': 40.90714285714291, 'ymax': 42.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"}, {'id': '[1740150059063, 219049]', 'time': '2025-02-21T15:00:59.063Z', 'level': 'error', 'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 10.84, 'xmax': 11.982857142857087, 'ymin': 40.90714285714291, 'ymax': 42.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"}, {'id': '[1740150059263, 190208]', 'time': '2025-02-21T15:00:59.263Z', 'level': 'error', 'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {'xmin': 10.84, 'xmax': 11.982857142857087, 'ymin': 40.90714285714291, 'ymax': 42.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\"}, {'id': '[1740150061490, 421112]', 'time': '2025-02-21T15:01:01.490Z', 'level': 'error', 'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 10.84, 'xmax': 11.982857142857087, 'ymin': 40.90714285714291, 'ymax': 42.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\"}, {'id': '[1740150061494, 576851]', 'time': '2025-02-21T15:01:01.494Z', 'level': 'error', 'message': 'Task 0 in stage 18.0 failed 4 times; aborting job'}, {'id': '[1740150061503, 290566]', 'time': '2025-02-21T15:01:01.503Z', 'level': 'error', 'message': 'Stage error: Job aborted due to stage failure: Task 0 in stage 18.0 failed 4 times, most recent failure: Lost task 0.3 in stage 18.0 (TID 139) (10.42.135.33 executor 2): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 10.84, \\'xmax\\': 11.982857142857087, \\'ymin\\': 40.90714285714291, \\'ymax\\': 42.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\\nDriver stacktrace:'}, {'id': '[1740150062931, 512198]', 'time': '2025-02-21T15:01:02.931Z', 'level': 'error', 'message': 'OpenEO batch job failed: Exception during Spark execution: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variabl...'}]\n",
      "Full logs can be inspected in an openEO (web) editor or with `connection.job('j-2502211459014f79a2b2228051b21290').logs()`.\n"
     ]
    },
    {
     "ename": "JobFailedException",
     "evalue": "Batch job 'j-2502211459014f79a2b2228051b21290' didn't finish successfully. Status: error (after 0:03:51).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJobFailedException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m job_options \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecutor-memory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3G\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecutor-memoryOverhead\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4G\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecutor-cores\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m }\n\u001b[0;32m----> 7\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[43mLST\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlst.nc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/evapo_sentinelhub/lib/python3.13/site-packages/openeo/rest/datacube.py:2406\u001b[0m, in \u001b[0;36mDataCube.execute_batch\u001b[0;34m(self, outputfile, out_format, print, max_poll_interval, connection_retry_interval, job_options, validate, auto_add_save_result, **format_options)\u001b[0m\n\u001b[1;32m   2396\u001b[0m     cube \u001b[38;5;241m=\u001b[39m _ensure_save_result(\n\u001b[1;32m   2397\u001b[0m         cube\u001b[38;5;241m=\u001b[39mcube,\n\u001b[1;32m   2398\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mout_format,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2402\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataCube.execute_batch()\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2403\u001b[0m     )\n\u001b[1;32m   2405\u001b[0m job \u001b[38;5;241m=\u001b[39m cube\u001b[38;5;241m.\u001b[39mcreate_job(job_options\u001b[38;5;241m=\u001b[39mjob_options, validate\u001b[38;5;241m=\u001b[39mvalidate, auto_add_save_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 2406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_synchronous\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2407\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2408\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_poll_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_poll_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_retry_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_retry_interval\u001b[49m\n\u001b[1;32m   2409\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/evapo_sentinelhub/lib/python3.13/site-packages/openeo/rest/job.py:242\u001b[0m, in \u001b[0;36mBatchJob.run_synchronous\u001b[0;34m(self, outputfile, print, max_poll_interval, connection_retry_interval)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_synchronous\u001b[39m(\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;28mself\u001b[39m, outputfile: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28mprint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mprint\u001b[39m, max_poll_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, connection_retry_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m\n\u001b[1;32m    240\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchJob:\n\u001b[1;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Start the job, wait for it to finish and download result\"\"\"\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_and_wait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_poll_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_poll_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_retry_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_retry_interval\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# TODO #135 support multi file result sets too?\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m outputfile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/evapo_sentinelhub/lib/python3.13/site-packages/openeo/rest/job.py:324\u001b[0m, in \u001b[0;36mBatchJob.start_and_wait\u001b[0;34m(self, print, max_poll_interval, connection_retry_interval, soft_error_max)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogs(level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mERROR))\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull logs can be inspected in an openEO (web) editor or with `connection.job(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m).logs()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JobFailedException(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt finish successfully. Status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    326\u001b[0m         job\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    327\u001b[0m     )\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mJobFailedException\u001b[0m: Batch job 'j-2502211459014f79a2b2228051b21290' didn't finish successfully. Status: error (after 0:03:51)."
     ]
    }
   ],
   "source": [
    "job_options = {\n",
    "    \"executor-memory\": \"3G\",\n",
    "    \"executor-memoryOverhead\": \"4G\",\n",
    "    \"executor-cores\": \"2\",\n",
    "}\n",
    "\n",
    "job = LST.execute_batch(\n",
    "    outputfile=\"lst.nc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "    if (!window.customElements || !window.customElements.get('openeo-logs')) {\n",
       "        var el = document.createElement('script');\n",
       "        el.src = \"https://cdn.jsdelivr.net/npm/@openeo/vue-components@2/assets/openeo.min.js\";\n",
       "        document.head.appendChild(el);\n",
       "\n",
       "        var font = document.createElement('font');\n",
       "        font.as = \"font\";\n",
       "        font.type = \"font/woff2\";\n",
       "        font.crossOrigin = true;\n",
       "        font.href = \"https://use.fontawesome.com/releases/v5.13.0/webfonts/fa-solid-900.woff2\"\n",
       "        document.head.appendChild(font);\n",
       "    }\n",
       "    </script>\n",
       "    <openeo-logs>\n",
       "        <script type=\"application/json\">{\"logs\": [{\"id\": \"[1740074183804, 429565]\", \"time\": \"2025-02-20T17:56:23.804Z\", \"level\": \"info\", \"message\": \"Starting batch job os.getpid()=79: start 2025-02-20 17:56:23.803986\"}, {\"id\": \"[1740074184872, 102543]\", \"time\": \"2025-02-20T17:56:24.872Z\", \"level\": \"info\", \"message\": \"Loaded config config_id='os_creodias_openeo_k8s_prod' from config_path='/opt/backend_config/backendconfig.py' (reason='lazy_load')\"}, {\"id\": \"[1740074185858, 235995]\", \"time\": \"2025-02-20T17:56:25.858Z\", \"level\": \"info\", \"message\": \"Logging initialized @9739ms to org.sparkproject.jetty.util.log.Slf4jLog\"}, {\"id\": \"[1740074197281, 669993]\", \"time\": \"2025-02-20T17:56:37.281Z\", \"level\": \"info\", \"message\": \"Job spec: {\\n \\\"process_graph\\\": {\\n  \\\"apply1\\\": {\\n   \\\"process_id\\\": \\\"apply\\\",\\n   \\\"arguments\\\": {\\n    \\\"process\\\": {\\n     \\\"process_graph\\\": {\\n      \\\"gte1\\\": {\\n       \\\"result\\\": true,\\n       \\\"process_id\\\": \\\"gte\\\",\\n       \\\"arguments\\\": {\\n        \\\"x\\\": {\\n         \\\"from_parameter\\\": \\\"x\\\"\\n        },\\n        \\\"y\\\": 16384\\n       }\\n      }\\n     }\\n    },\\n    \\\"data\\\": {\\n     \\\"from_node\\\": \\\"loadcollection2\\\"\\n    }\\n   }\\n  },\\n  \\\"loadcollection1\\\": {\\n   \\\"process_id\\\": \\\"load_collection\\\",\\n   \\\"arguments\\\": {\\n    \\\"temporal_extent\\\": [\\n     \\\"2020-01-01\\\",\\n     \\\"2020-03-01\\\"\\n    ],\\n    \\\"spatial_extent\\\": {\\n     \\\"east\\\": 14.3,\\n     \\\"south\\\": 51.7,\\n     \\\"north\\\": 52.05,\\n     \\\"west\\\": 13.84\\n    },\\n    \\\"id\\\": \\\"SENTINEL3_SLSTR_L2_LST\\\",\\n    \\\"bands\\\": [\\n     \\\"LST\\\"\\n    ]\\n   }\\n  },\\n  \\\"mask1\\\": {\\n   \\\"process_id\\\": \\\"mask\\\",\\n   \\\"arguments\\\": {\\n    \\\"data\\\": {\\n     \\\"from_node\\\": \\\"loadcollection1\\\"\\n    },\\n    \\\"mask\\\": {\\n     \\\"from_node\\\": \\\"apply1\\\"\\n    }\\n   }\\n  },\\n  \\\"saveresult1\\\": {\\n   \\\"result\\\": true,\\n   \\\"process_id\\\": \\\"save_result\\\",\\n   \\\"arguments\\\": {\\n    \\\"data\\\": {\\n     \\\"from_node\\\": \\\"mask1\\\"\\n    },\\n    \\\"format\\\": \\\"netCDF\\\",\\n    \\\"options\\\": {}\\n   }\\n  },\\n  \\\"loadcollection2\\\": {\\n   \\\"process_id\\\": \\\"load_collection\\\",\\n   \\\"arguments\\\": {\\n    \\\"temporal_extent\\\": [\\n     \\\"2020-01-01\\\",\\n     \\\"2020-03-01\\\"\\n    ],\\n    \\\"spatial_extent\\\": {\\n     \\\"east\\\": 14.3,\\n     \\\"south\\\": 51.7,\\n     \\\"north\\\": 52.05,\\n     \\\"west\\\": 13.84\\n    },\\n    \\\"id\\\": \\\"SENTINEL3_SLSTR_L2_LST\\\",\\n    \\\"bands\\\": [\\n     \\\"confidence_in\\\"\\n    ]\\n   }\\n  }\\n },\\n \\\"job_options\\\": {\\n  \\\"log_level\\\": \\\"info\\\"\\n }\\n}\"}, {\"id\": \"[1740074199280, 777481]\", \"time\": \"2025-02-20T17:56:39.280Z\", \"level\": \"warning\", \"message\": \"No elastic_job_registry given to GeoPySparkBackendImplementation, creating one\"}, {\"id\": \"[1740074199422, 99089]\", \"time\": \"2025-02-20T17:56:39.422Z\", \"level\": \"info\", \"message\": \"Doing 'client_credentials' token request 'https://sso.terrascope.be/auth/realms/terrascope/protocol/openid-connect/token' with post data fields ['grant_type', 'client_id', 'client_secret', 'scope'] (client_id 'openeo-elastic-job-registry')\"}, {\"id\": \"[1740074199841, 343263]\", \"time\": \"2025-02-20T17:56:39.841Z\", \"level\": \"info\", \"message\": \"EJR health check {'status': 'ok', 'info': {'elasticsearch-ping': {'status': 'up'}, 'elasticsearch-health': {'status': 'up'}, 'auth': {'status': 'up', 'state': 'ok'}}, 'error': {}, 'details': {}}\"}, {\"id\": \"[1740074200914, 457019]\", \"time\": \"2025-02-20T17:56:40.914Z\", \"level\": \"info\", \"message\": \"Loaded config config_id='os_creodias_openeo_k8s_prod' from config_path='/opt/backend_config/backendconfig.py' (reason='lazy_load')\"}, {\"id\": \"[1740074200914, 697425]\", \"time\": \"2025-02-20T17:56:40.914Z\", \"level\": \"info\", \"message\": \"Correlation id: j-250220175546475684630774e1358c51\"}, {\"id\": \"[1740074200915, 757908]\", \"time\": \"2025-02-20T17:56:40.915Z\", \"level\": \"info\", \"message\": \"Doing dry run\"}, {\"id\": \"[1740074200917, 156002]\", \"time\": \"2025-02-20T17:56:40.917Z\", \"level\": \"info\", \"message\": \"Dry run extracted these source constraints: [(('load_collection', ('SENTINEL3_SLSTR_L2_LST', (('productType', (('eq', 'SL_2_LST___'),)),), ('confidence_in',))), {'temporal_extent': ('2020-01-01', '2020-03-01'), 'spatial_extent': {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'}, 'bands': ['confidence_in'], 'properties': {'productType': {'process_graph': {'eq1': {'process_id': 'eq', 'arguments': {'x': {'from_parameter': 'value'}, 'y': 'SL_2_LST___'}, 'result': True}}}}}), (('load_collection', ('SENTINEL3_SLSTR_L2_LST', (('productType', (('eq', 'SL_2_LST___'),)),), ('LST',))), {'temporal_extent': ('2020-01-01', '2020-03-01'), 'spatial_extent': {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'}, 'bands': ['LST'], 'properties': {'productType': {'process_graph': {'eq1': {'process_id': 'eq', 'arguments': {'x': {'from_parameter': 'value'}, 'y': 'SL_2_LST___'}, 'result': True}}}}})]\"}, {\"id\": \"[1740074200917, 477904]\", \"time\": \"2025-02-20T17:56:40.917Z\", \"level\": \"info\", \"message\": \"load_collection: start 2025-02-20 17:56:40.917252\"}, {\"id\": \"[1740074200937, 773216]\", \"time\": \"2025-02-20T17:56:40.937Z\", \"level\": \"info\", \"message\": \"load_collection: Creating raster datacube for SENTINEL3_SLSTR_L2_LST with arguments {'temporal_extent': ('2020-01-01', '2020-03-01'), 'spatial_extent': {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'}, 'global_extent': {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'}, 'bands': ['confidence_in'], 'properties': {'productType': {'process_graph': {'eq1': {'process_id': 'eq', 'arguments': {'x': {'from_parameter': 'value'}, 'y': 'SL_2_LST___'}, 'result': True}}}}, 'aggregate_spatial_geometries': None, 'sar_backscatter': None, 'process_types': set(), 'custom_mask': {}, 'data_mask': None, 'target_crs': None, 'target_resolution': None, 'resample_method': 'near', 'pixel_buffer': None}, environment: {'vault_token': None, 'sentinel_hub_client_alias': None, 'max_soft_errors_ratio': 0.1, 'dependencies': [], 'pyramid_levels': 'highest', 'require_bounds': True, 'correlation_id': 'j-250220175546475684630774e1358c51', 'user': User('d60dac41-2704-47b5-8f58-23f58c3b8f8e', None)}\"}, {\"id\": \"[1740074200938, 825203]\", \"time\": \"2025-02-20T17:56:40.938Z\", \"level\": \"info\", \"message\": \"Detected process types:set()\"}, {\"id\": \"[1740074200938, 902931]\", \"time\": \"2025-02-20T17:56:40.938Z\", \"level\": \"info\", \"message\": \"Correlation ID is 'j-250220175546475684630774e1358c51'\"}, {\"id\": \"[1740074207627, 38722]\", \"time\": \"2025-02-20T17:56:47.627Z\", \"level\": \"info\", \"message\": \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel3/search.json?box=13.84%2C51.7%2C14.3%2C52.05&page=1&maxRecords=1000&status=ONLINE&dataset=ESA-DATASET&productType=SL_2_LST___&startDate=2020-01-01T00%3A00%3A00Z&completionDate=2020-02-29T23%3A59%3A59.999999999Z returned 200\"}, {\"id\": \"[1740074211655, 45837]\", \"time\": \"2025-02-20T17:56:51.655Z\", \"level\": \"info\", \"message\": \"Starting stage: 0 - mapValues at ClipToGrid.scala:92. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074216731, 423045]\", \"time\": \"2025-02-20T17:56:56.731Z\", \"level\": \"info\", \"message\": \"Starting stage: 1 - distinct at FileRDDFactory.scala:100. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074216843, 20501]\", \"time\": \"2025-02-20T17:56:56.843Z\", \"level\": \"warning\", \"message\": \"Stage 1 contains a task of very large size (1057 KiB). The maximum recommended task size is 1000 KiB.\"}, {\"id\": \"[1740074217725, 350244]\", \"time\": \"2025-02-20T17:56:57.725Z\", \"level\": \"info\", \"message\": \"Starting stage: 2 - collect at FileRDDFactory.scala:100. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074218112, 460944]\", \"time\": \"2025-02-20T17:56:58.112Z\", \"level\": \"info\", \"message\": \"Convert JavaObject id=o1919 to geopyspark.Metadata\"}, {\"id\": \"[1740074218236, 724342]\", \"time\": \"2025-02-20T17:56:58.236Z\", \"level\": \"info\", \"message\": \"Starting stage: 4 - filter at FileRDDFactory.scala:94. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074218255, 859655]\", \"time\": \"2025-02-20T17:56:58.255Z\", \"level\": \"warning\", \"message\": \"Stage 4 contains a task of very large size (1057 KiB). The maximum recommended task size is 1000 KiB.\"}, {\"id\": \"[1740074218776, 226460]\", \"time\": \"2025-02-20T17:56:58.776Z\", \"level\": \"info\", \"message\": \"Starting stage: 5 - groupByKey at /opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py:138. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074221753, 784120]\", \"time\": \"2025-02-20T17:57:01.753Z\", \"level\": \"info\", \"message\": \"Starting stage: 6 - collect at /opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py:140. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074222954, 287188]\", \"time\": \"2025-02-20T17:57:02.954Z\", \"level\": \"info\", \"message\": \"Constructing TiledRasterLayer from numpy rdd, with metadata Metadata(Bounds(minKey=SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 1, 1, 0, 0)), maxKey=SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 2, 29, 23, 59))), float32, nan, +proj=longlat +datum=WGS84 +no_defs , Extent(xmin=13.84, ymin=51.7, xmax=14.3, ymax=52.05), TileLayout(layoutCols=1, layoutRows=1, tileCols=128, tileRows=128), LayoutDefinition(extent=Extent(xmin=13.84, ymin=50.90714285714291, xmax=14.982857142857087, ymax=52.05), tileLayout=TileLayout(layoutCols=1, layoutRows=1, tileCols=128, tileRows=128)))\"}, {\"id\": \"[1740074223288, 129117]\", \"time\": \"2025-02-20T17:57:03.288Z\", \"level\": \"info\", \"message\": \"load_collection: end 2025-02-20 17:57:03.287514, elapsed 0:00:22.370262\"}, {\"id\": \"[1740074223397, 804054]\", \"time\": \"2025-02-20T17:57:03.397Z\", \"level\": \"info\", \"message\": \"load_collection: start 2025-02-20 17:57:03.396822\"}, {\"id\": \"[1740074223419, 361437]\", \"time\": \"2025-02-20T17:57:03.419Z\", \"level\": \"info\", \"message\": \"load_collection: Creating raster datacube for SENTINEL3_SLSTR_L2_LST with arguments {'temporal_extent': ('2020-01-01', '2020-03-01'), 'spatial_extent': {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'}, 'global_extent': {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'}, 'bands': ['LST'], 'properties': {'productType': {'process_graph': {'eq1': {'process_id': 'eq', 'arguments': {'x': {'from_parameter': 'value'}, 'y': 'SL_2_LST___'}, 'result': True}}}}, 'aggregate_spatial_geometries': None, 'sar_backscatter': None, 'process_types': set(), 'custom_mask': {}, 'data_mask': <openeogeotrellis.geopysparkdatacube.GeopysparkDataCube object at 0x7f01b99ed280>, 'target_crs': None, 'target_resolution': None, 'resample_method': 'near', 'pixel_buffer': None}, environment: {'vault_token': None, 'sentinel_hub_client_alias': None, 'max_soft_errors_ratio': 0.1, 'dependencies': [], 'pyramid_levels': 'highest', 'require_bounds': True, 'correlation_id': 'j-250220175546475684630774e1358c51', 'user': User('d60dac41-2704-47b5-8f58-23f58c3b8f8e', None)}\"}, {\"id\": \"[1740074223420, 84067]\", \"time\": \"2025-02-20T17:57:03.420Z\", \"level\": \"info\", \"message\": \"Detected process types:set()\"}, {\"id\": \"[1740074223420, 659552]\", \"time\": \"2025-02-20T17:57:03.420Z\", \"level\": \"info\", \"message\": \"Correlation ID is 'j-250220175546475684630774e1358c51'\"}, {\"id\": \"[1740074228614, 207118]\", \"time\": \"2025-02-20T17:57:08.614Z\", \"level\": \"info\", \"message\": \"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel3/search.json?box=13.84%2C51.7%2C14.3%2C52.05&page=1&maxRecords=1000&status=ONLINE&dataset=ESA-DATASET&productType=SL_2_LST___&startDate=2020-01-01T00%3A00%3A00Z&completionDate=2020-02-29T23%3A59%3A59.999999999Z returned 200\"}, {\"id\": \"[1740074229181, 955338]\", \"time\": \"2025-02-20T17:57:09.181Z\", \"level\": \"info\", \"message\": \"Starting stage: 7 - mapValues at ClipToGrid.scala:92. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074231304, 111573]\", \"time\": \"2025-02-20T17:57:11.304Z\", \"level\": \"info\", \"message\": \"Starting stage: 8 - distinct at FileRDDFactory.scala:100. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074231894, 517126]\", \"time\": \"2025-02-20T17:57:11.894Z\", \"level\": \"info\", \"message\": \"Starting stage: 9 - collect at FileRDDFactory.scala:100. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074232211, 459885]\", \"time\": \"2025-02-20T17:57:12.211Z\", \"level\": \"info\", \"message\": \"Convert JavaObject id=o2032 to geopyspark.Metadata\"}, {\"id\": \"[1740074232252, 348718]\", \"time\": \"2025-02-20T17:57:12.252Z\", \"level\": \"info\", \"message\": \"Starting stage: 11 - filter at FileRDDFactory.scala:94. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074232566, 522386]\", \"time\": \"2025-02-20T17:57:12.566Z\", \"level\": \"info\", \"message\": \"Starting stage: 12 - groupByKey at /opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py:138. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074234779, 735154]\", \"time\": \"2025-02-20T17:57:14.779Z\", \"level\": \"info\", \"message\": \"Starting stage: 13 - collect at /opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py:140. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074235907, 279390]\", \"time\": \"2025-02-20T17:57:15.907Z\", \"level\": \"info\", \"message\": \"Constructing TiledRasterLayer from numpy rdd, with metadata Metadata(Bounds(minKey=SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 1, 1, 0, 0)), maxKey=SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 2, 29, 23, 59))), float32, nan, +proj=longlat +datum=WGS84 +no_defs , Extent(xmin=13.84, ymin=51.7, xmax=14.3, ymax=52.05), TileLayout(layoutCols=1, layoutRows=1, tileCols=128, tileRows=128), LayoutDefinition(extent=Extent(xmin=13.84, ymin=50.90714285714291, xmax=14.982857142857087, ymax=52.05), tileLayout=TileLayout(layoutCols=1, layoutRows=1, tileCols=128, tileRows=128)))\"}, {\"id\": \"[1740074235940, 422572]\", \"time\": \"2025-02-20T17:57:15.940Z\", \"level\": \"info\", \"message\": \"load_collection: end 2025-02-20 17:57:15.940109, elapsed 0:00:12.543287\"}, {\"id\": \"[1740074235941, 163204]\", \"time\": \"2025-02-20T17:57:15.941Z\", \"level\": \"info\", \"message\": \"Evaluated process graph, result (type <class 'openeo_driver.save_result.ImageCollectionResult'>): <openeo_driver.save_result.ImageCollectionResult object at 0x7f01b99edcd0>\"}, {\"id\": \"[1740074235941, 664722]\", \"time\": \"2025-02-20T17:57:15.941Z\", \"level\": \"info\", \"message\": \"Extracting result metadata from <DryRunDataTracer (traces: [<DataSource#139646656371712('load_collection', ('SENTINEL3_SLSTR_L2_LST', {'productType': {'eq': 'SL_2_LST___'}}, ['confidence_in']))>, <DataTrace#139645765505168(#139646656371712, temporal_extent, ('2020-01-01', '2020-03-01'))>, <DataTrace#139646656410864(#139645765505168, spatial_extent, {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'})>, <DataTrace#139646656410544(#139646656410864, bands, ['confidence_in'])>, <DataTrace#139646656410304(#139646656410544, properties, {'productType': {'process_graph': {'eq1': {'process_id': 'eq', 'arguments': {'x': {'from_parameter': 'value'}, 'y': 'SL_2_LST___'}, 'result': True}}}})>, <DataTrace#139646656410464(#139646656410304, apply, {})>, <DataSource#139645764225344('load_collection', ('SENTINEL3_SLSTR_L2_LST', {'productType': {'eq': 'SL_2_LST___'}}, ['LST']))>, <DataTrace#139646656410704(#139645764225344, temporal_extent, ('2020-01-01', '2020-03-01'))>, <DataTrace#139645385357248(#139646656410704, spatial_extent, {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'})>, <DataTrace#139645385357328(#139645385357248, bands, ['LST'])>, <DataTrace#139645385357408(#139645385357328, properties, {'productType': {'process_graph': {'eq1': {'process_id': 'eq', 'arguments': {'x': {'from_parameter': 'value'}, 'y': 'SL_2_LST___'}, 'result': True}}}})>, <DataTrace#139645385357488(#139646656410464, resample_cube_spatial, {'target': <openeo_driver.dry_run.DryRunDataCube object at 0x7f01d02b3d30>, 'method': 'near'})>, <DataTrace#139645385357568(#139645385357408, mask, {'mask': <openeo_driver.dry_run.DryRunDataCube object at 0x7f01d034ef70>})>])>\"}, {\"id\": \"[1740074236146, 533599]\", \"time\": \"2025-02-20T17:57:16.146Z\", \"level\": \"info\", \"message\": \"input asset hrefs: {}\"}, {\"id\": \"[1740074236151, 299562]\", \"time\": \"2025-02-20T17:57:16.151Z\", \"level\": \"info\", \"message\": \"output asset hrefs: {}\"}, {\"id\": \"[1740074236262, 301907]\", \"time\": \"2025-02-20T17:57:16.262Z\", \"level\": \"info\", \"message\": \"wrote metadata to /batch_jobs/j-250220175546475684630774e1358c51/job_metadata.json\"}, {\"id\": \"[1740074236318, 589765]\", \"time\": \"2025-02-20T17:57:16.318Z\", \"level\": \"info\", \"message\": \"save_result format NETCDF with bounds Extent(xmin=13.84, ymin=51.7, xmax=14.3, ymax=52.05) and options {'batch_mode': True, 'file_metadata': {'title': '', 'description': '', 'institution': 'openEO platform - Geotrellis backend: 0.60.1a1'}}\"}, {\"id\": \"[1740074236459, 950919]\", \"time\": \"2025-02-20T17:57:16.459Z\", \"level\": \"info\", \"message\": \"Starting stage: 17 - partitionBy at /opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py:143. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074237620, 686331]\", \"time\": \"2025-02-20T17:57:17.620Z\", \"level\": \"info\", \"message\": \"Starting stage: 18 - RDD at ContextRDD.scala:32. \\nStages may combine multiple processes.\"}, {\"id\": \"[1740074239097, 731755]\", \"time\": \"2025-02-20T17:57:19.097Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7f20d5b520d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074239406, 824764]\", \"time\": \"2025-02-20T17:57:19.406Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577957541006].\"}, {\"id\": \"[1740074239407, 1215]\", \"time\": \"2025-02-20T17:57:19.407Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074239407, 348285]\", \"time\": \"2025-02-20T17:57:19.407Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074243340, 315313]\", \"time\": \"2025-02-20T17:57:23.340Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7fca7ddaa0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074243491, 714624]\", \"time\": \"2025-02-20T17:57:23.491Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578302916987].\"}, {\"id\": \"[1740074243492, 355880]\", \"time\": \"2025-02-20T17:57:23.492Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074243492, 624884]\", \"time\": \"2025-02-20T17:57:23.492Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074244163, 224587]\", \"time\": \"2025-02-20T17:57:24.163Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7ff31c05c0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074244642, 292651]\", \"time\": \"2025-02-20T17:57:24.642Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074244642, 984183]\", \"time\": \"2025-02-20T17:57:24.642Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577903007981].\"}, {\"id\": \"[1740074244643, 836771]\", \"time\": \"2025-02-20T17:57:24.643Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074246009, 348549]\", \"time\": \"2025-02-20T17:57:26.009Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\"}, {\"id\": \"[1740074246061, 785480]\", \"time\": \"2025-02-20T17:57:26.061Z\", \"level\": \"warning\", \"message\": \"Lost task 0.0 in stage 18.0 (TID 124) (10.42.247.49 executor 2): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}, {\"id\": \"[1740074246068, 903776]\", \"time\": \"2025-02-20T17:57:26.068Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@773bf61f,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@5e0969b3),Vector(AccumulableInfo(458,None,Some(8366),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(0),None,false,true,None), AccumulableInfo(468,None,Some(1),None,false,true,None), AccumulableInfo(469,None,Some(0),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(379),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(0),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 8366), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 0), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 1), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 0), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 379), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 0), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(519433024, 109109976, 32768, 0, 111250, 0, 144018, 0, 8466456, 0, 8568983552, 1279995904, 2553823232, 1838415872, 0, 0, 1, 23, 3, 209, 232))\"}, {\"id\": \"[1740074246115, 8398]\", \"time\": \"2025-02-20T17:57:26.115Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7f3ec140a0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074246244, 113792]\", \"time\": \"2025-02-20T17:57:26.244Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/05/S3B_SL_2_LST____20200105T204856_20200105T205156_20200822T062510_0179_034_100_0720_LR1_R_NT_004.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074246244, 350560]\", \"time\": \"2025-02-20T17:57:26.244Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578257336187].\"}, {\"id\": \"[1740074246244, 607388]\", \"time\": \"2025-02-20T17:57:26.244Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074246645, 46123]\", \"time\": \"2025-02-20T17:57:26.645Z\", \"level\": \"info\", \"message\": \"bbox_original=[nan, nan, nan, nan] source_coordinates=array([[14.967985, 50.913097],\\n       [14.956885, 50.907986],\\n       [14.899737, 50.907303],\\n       ...,\\n       [13.869297, 52.042343],\\n       [13.848849, 52.04699 ],\\n       [13.845058, 52.039783]], dtype=float32)\"}, {\"id\": \"[1740074246645, 817184]\", \"time\": \"2025-02-20T17:57:26.645Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/05/S3B_SL_2_LST____20200105T204856_20200105T205156_20200822T062510_0179_034_100_0720_LR1_R_NT_004.SEN3/geodetic_tx.nc\"}, {\"id\": \"[1740074246807, 165617]\", \"time\": \"2025-02-20T17:57:26.807Z\", \"level\": \"info\", \"message\": \"Reprojecting SL_2_LST___\"}, {\"id\": \"[1740074246807, 798929]\", \"time\": \"2025-02-20T17:57:26.807Z\", \"level\": \"info\", \"message\": \"Creating LUT with shape (129, 129, 2)\"}, {\"id\": \"[1740074246817, 611159]\", \"time\": \"2025-02-20T17:57:26.817Z\", \"level\": \"info\", \"message\": \"Creating LUT with shape (250, 249, 2)\"}, {\"id\": \"[1740074246836, 718775]\", \"time\": \"2025-02-20T17:57:26.836Z\", \"level\": \"info\", \"message\": \" Reprojecting LST_in:LST\"}, {\"id\": \"[1740074246836, 945748]\", \"time\": \"2025-02-20T17:57:26.836Z\", \"level\": \"debug\", \"message\": \"Reading LST from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/05/S3B_SL_2_LST____20200105T204856_20200105T205156_20200822T062510_0179_034_100_0720_LR1_R_NT_004.SEN3/LST_in.nc\"}, {\"id\": \"[1740074247088, 202268]\", \"time\": \"2025-02-20T17:57:27.088Z\", \"level\": \"info\", \"message\": \" Split (1, 129, 129) in tiles of 128\"}, {\"id\": \"[1740074247088, 239531]\", \"time\": \"2025-02-20T17:57:27.088Z\", \"level\": \"info\", \"message\": \"Done reprojecting SL_2_LST___\"}, {\"id\": \"[1740074247088, 342367]\", \"time\": \"2025-02-20T17:57:27.088Z\", \"level\": \"info\", \"message\": \" Layout extent split in 1 tiles\"}, {\"id\": \"[1740074247088, 693588]\", \"time\": \"2025-02-20T17:57:27.088Z\", \"level\": \"info\", \"message\": \" Create Tile for key SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 1, 5, 20, 48)) from (1, 128, 128)\"}, {\"id\": \"[1740074247397, 750566]\", \"time\": \"2025-02-20T17:57:27.397Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7f20d5b4d0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074247467, 12614]\", \"time\": \"2025-02-20T17:57:27.467Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074247467, 96002]\", \"time\": \"2025-02-20T17:57:27.467Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578301190651].\"}, {\"id\": \"[1740074247468, 870778]\", \"time\": \"2025-02-20T17:57:27.468Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3B_SL_2_LST____20200106T085951_20200106T090251_20200822T063325_0179_034_107_2160_LR1_R_NT_004.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074247742, 304806]\", \"time\": \"2025-02-20T17:57:27.742Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"}, {\"id\": \"[1740074247804, 520007]\", \"time\": \"2025-02-20T17:57:27.804Z\", \"level\": \"warning\", \"message\": \"Lost task 2.0 in stage 18.0 (TID 126) (10.42.243.240 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}, {\"id\": \"[1740074247812, 328703]\", \"time\": \"2025-02-20T17:57:27.812Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@5a35f2a6,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@1f18ccc6),Vector(AccumulableInfo(458,None,Some(6358),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(380),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(25),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(27),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 6358), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 380), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 25), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 27), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(353200280, 107880248, 32768, 0, 25829, 0, 58597, 0, 8472245, 0, 8546746368, 1311604736, 703438848, 175988736, 0, 0, 1, 28, 3, 222, 250))\"}, {\"id\": \"[1740074247859, 226803]\", \"time\": \"2025-02-20T17:57:27.859Z\", \"level\": \"info\", \"message\": \"bbox_original=[nan, nan, nan, nan] source_coordinates=array([[14.918253, 52.042156],\\n       [14.942972, 52.046215],\\n       [14.955179, 52.047615],\\n       ...,\\n       [13.874681, 50.91082 ],\\n       [13.899852, 50.91349 ],\\n       [13.850042, 50.908043]], dtype=float32)\"}, {\"id\": \"[1740074247860, 984572]\", \"time\": \"2025-02-20T17:57:27.860Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3B_SL_2_LST____20200106T085951_20200106T090251_20200822T063325_0179_034_107_2160_LR1_R_NT_004.SEN3/geodetic_tx.nc\"}, {\"id\": \"[1740074248052, 426935]\", \"time\": \"2025-02-20T17:57:28.052Z\", \"level\": \"info\", \"message\": \"Creating LUT with shape (129, 129, 2)\"}, {\"id\": \"[1740074248052, 484105]\", \"time\": \"2025-02-20T17:57:28.052Z\", \"level\": \"info\", \"message\": \"Reprojecting SL_2_LST___\"}, {\"id\": \"[1740074248069, 85175]\", \"time\": \"2025-02-20T17:57:28.069Z\", \"level\": \"info\", \"message\": \"Creating LUT with shape (250, 249, 2)\"}, {\"id\": \"[1740074248108, 46702]\", \"time\": \"2025-02-20T17:57:28.108Z\", \"level\": \"info\", \"message\": \" Reprojecting LST_in:LST\"}, {\"id\": \"[1740074248108, 83202]\", \"time\": \"2025-02-20T17:57:28.108Z\", \"level\": \"debug\", \"message\": \"Reading LST from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3B_SL_2_LST____20200106T085951_20200106T090251_20200822T063325_0179_034_107_2160_LR1_R_NT_004.SEN3/LST_in.nc\"}, {\"id\": \"[1740074248564, 698982]\", \"time\": \"2025-02-20T17:57:28.564Z\", \"level\": \"info\", \"message\": \"Done reprojecting SL_2_LST___\"}, {\"id\": \"[1740074248566, 41598]\", \"time\": \"2025-02-20T17:57:28.566Z\", \"level\": \"info\", \"message\": \" Split (1, 129, 129) in tiles of 128\"}, {\"id\": \"[1740074248566, 110590]\", \"time\": \"2025-02-20T17:57:28.566Z\", \"level\": \"info\", \"message\": \" Create Tile for key SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 1, 6, 8, 59)) from (1, 128, 128)\"}, {\"id\": \"[1740074248566, 363570]\", \"time\": \"2025-02-20T17:57:28.566Z\", \"level\": \"info\", \"message\": \" Layout extent split in 1 tiles\"}, {\"id\": \"[1740074248803, 793107]\", \"time\": \"2025-02-20T17:57:28.803Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578302916987].\"}, {\"id\": \"[1740074248804, 805991]\", \"time\": \"2025-02-20T17:57:28.804Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074248804, 995636]\", \"time\": \"2025-02-20T17:57:28.804Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074248988, 655092]\", \"time\": \"2025-02-20T17:57:28.988Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"}, {\"id\": \"[1740074249029, 836120]\", \"time\": \"2025-02-20T17:57:29.029Z\", \"level\": \"warning\", \"message\": \"Lost task 1.0 in stage 18.0 (TID 125) (10.42.231.60 executor 3): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}, {\"id\": \"[1740074249033, 255690]\", \"time\": \"2025-02-20T17:57:29.033Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@373b5a34,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@226ae991),Vector(AccumulableInfo(458,None,Some(7605),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(375),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(42),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 7605), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 375), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 42), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(347631296, 89424440, 32768, 0, 25829, 0, 58597, 0, 4247018, 0, 8101117952, 720412672, 2005319680, 954257408, 0, 0, 0, 0, 3, 246, 246))\"}, {\"id\": \"[1740074249502, 854227]\", \"time\": \"2025-02-20T17:57:29.502Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074249502, 885484]\", \"time\": \"2025-02-20T17:57:29.502Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577903007981].\"}, {\"id\": \"[1740074249503, 168769]\", \"time\": \"2025-02-20T17:57:29.503Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074251054, 336267]\", \"time\": \"2025-02-20T17:57:31.054Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7ff31c05c0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074251126, 361884]\", \"time\": \"2025-02-20T17:57:31.126Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074251126, 408808]\", \"time\": \"2025-02-20T17:57:31.126Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577957541006].\"}, {\"id\": \"[1740074251127, 396216]\", \"time\": \"2025-02-20T17:57:31.127Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074251616, 832805]\", \"time\": \"2025-02-20T17:57:31.616Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7fca7dda60d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074251695, 86405]\", \"time\": \"2025-02-20T17:57:31.695Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074251695, 369951]\", \"time\": \"2025-02-20T17:57:31.695Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578597447268].\"}, {\"id\": \"[1740074251696, 366003]\", \"time\": \"2025-02-20T17:57:31.696Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074252995, 989010]\", \"time\": \"2025-02-20T17:57:32.995Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"}, {\"id\": \"[1740074253018, 443047]\", \"time\": \"2025-02-20T17:57:33.018Z\", \"level\": \"warning\", \"message\": \"Lost task 2.1 in stage 18.0 (TID 129) (10.42.247.49 executor 2): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}, {\"id\": \"[1740074253026, 127878]\", \"time\": \"2025-02-20T17:57:33.026Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@573f8fb8,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@e181765),Vector(AccumulableInfo(458,None,Some(4234),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(0),None,false,true,None), AccumulableInfo(468,None,Some(1),None,false,true,None), AccumulableInfo(469,None,Some(0),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(380),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(0),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 4234), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 0), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 1), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 0), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 380), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 0), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\"}, {\"id\": \"[1740074253163, 854369]\", \"time\": \"2025-02-20T17:57:33.163Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"}, {\"id\": \"[1740074253199, 794546]\", \"time\": \"2025-02-20T17:57:33.199Z\", \"level\": \"warning\", \"message\": \"Lost task 1.1 in stage 18.0 (TID 130) (10.42.16.189 executor 4): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}, {\"id\": \"[1740074253201, 159000]\", \"time\": \"2025-02-20T17:57:33.201Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@631f1668,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@164c5dfb),Vector(AccumulableInfo(458,None,Some(3777),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(375),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(3),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 3777), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 375), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 3), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\"}, {\"id\": \"[1740074254275, 137208]\", \"time\": \"2025-02-20T17:57:34.275Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7f20d5b4d0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074254334, 556182]\", \"time\": \"2025-02-20T17:57:34.334Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074254334, 978033]\", \"time\": \"2025-02-20T17:57:34.334Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578426994251].\"}, {\"id\": \"[1740074254335, 497759]\", \"time\": \"2025-02-20T17:57:34.335Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/07/S3B_SL_2_LST____20200107T195634_20200107T195934_20200822T070206_0179_034_128_0720_LR1_R_NT_004.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074254689, 766557]\", \"time\": \"2025-02-20T17:57:34.689Z\", \"level\": \"info\", \"message\": \"bbox_original=[nan, nan, nan, nan] source_coordinates=array([[14.979879, 50.912243],\\n       [14.979879, 50.912243],\\n       [14.963945, 50.91541 ],\\n       ...,\\n       [13.860534, 51.846485],\\n       [13.860534, 51.846485],\\n       [13.840284, 51.846394]], dtype=float32)\"}, {\"id\": \"[1740074254690, 748477]\", \"time\": \"2025-02-20T17:57:34.690Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/07/S3B_SL_2_LST____20200107T195634_20200107T195934_20200822T070206_0179_034_128_0720_LR1_R_NT_004.SEN3/geodetic_tx.nc\"}, {\"id\": \"[1740074254831, 321693]\", \"time\": \"2025-02-20T17:57:34.831Z\", \"level\": \"info\", \"message\": \"Creating LUT with shape (129, 129, 2)\"}, {\"id\": \"[1740074254831, 636999]\", \"time\": \"2025-02-20T17:57:34.831Z\", \"level\": \"info\", \"message\": \"Reprojecting SL_2_LST___\"}, {\"id\": \"[1740074254840, 803299]\", \"time\": \"2025-02-20T17:57:34.840Z\", \"level\": \"info\", \"message\": \"Creating LUT with shape (250, 249, 2)\"}, {\"id\": \"[1740074254856, 459692]\", \"time\": \"2025-02-20T17:57:34.856Z\", \"level\": \"info\", \"message\": \" Reprojecting LST_in:LST\"}, {\"id\": \"[1740074254856, 719637]\", \"time\": \"2025-02-20T17:57:34.856Z\", \"level\": \"debug\", \"message\": \"Reading LST from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/07/S3B_SL_2_LST____20200107T195634_20200107T195934_20200822T070206_0179_034_128_0720_LR1_R_NT_004.SEN3/LST_in.nc\"}, {\"id\": \"[1740074255015, 32798]\", \"time\": \"2025-02-20T17:57:35.015Z\", \"level\": \"info\", \"message\": \" Layout extent split in 1 tiles\"}, {\"id\": \"[1740074255015, 49723]\", \"time\": \"2025-02-20T17:57:35.015Z\", \"level\": \"info\", \"message\": \"Done reprojecting SL_2_LST___\"}, {\"id\": \"[1740074255015, 383355]\", \"time\": \"2025-02-20T17:57:35.015Z\", \"level\": \"info\", \"message\": \" Create Tile for key SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 1, 7, 19, 56)) from (1, 128, 128)\"}, {\"id\": \"[1740074255015, 459389]\", \"time\": \"2025-02-20T17:57:35.015Z\", \"level\": \"info\", \"message\": \" Split (1, 129, 129) in tiles of 128\"}, {\"id\": \"[1740074255133, 814865]\", \"time\": \"2025-02-20T17:57:35.133Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577903007981].\"}, {\"id\": \"[1740074255133, 816081]\", \"time\": \"2025-02-20T17:57:35.133Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074255133, 857280]\", \"time\": \"2025-02-20T17:57:35.133Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074255380, 717416]\", \"time\": \"2025-02-20T17:57:35.380Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\"}, {\"id\": \"[1740074255416, 343988]\", \"time\": \"2025-02-20T17:57:35.416Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@3d2552c5,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@73c8c93b),Vector(AccumulableInfo(458,None,Some(5995),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(379),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(5),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 5995), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 379), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 5), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\"}, {\"id\": \"[1740074255950, 247261]\", \"time\": \"2025-02-20T17:57:35.950Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\"}, {\"id\": \"[1740074255963, 606523]\", \"time\": \"2025-02-20T17:57:35.963Z\", \"level\": \"warning\", \"message\": \"Lost task 5.0 in stage 18.0 (TID 132) (10.42.243.240 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}, {\"id\": \"[1740074255981, 29591]\", \"time\": \"2025-02-20T17:57:35.981Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@68ff3d7c,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@1c28061d),Vector(AccumulableInfo(458,None,Some(6565),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(381),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(3),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 6565), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 381), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 3), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(410118112, 108423984, 32768, 0, 25829, 0, 58597, 0, 8474696, 0, 8546885632, 1312264192, 1179045888, 388788224, 0, 0, 1, 28, 3, 222, 250))\"}, {\"id\": \"[1740074257836, 554303]\", \"time\": \"2025-02-20T17:57:37.836Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7f3ec140a0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074257915, 740985]\", \"time\": \"2025-02-20T17:57:37.915Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578993668796].\"}, {\"id\": \"[1740074257916, 106211]\", \"time\": \"2025-02-20T17:57:37.916Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074257916, 419843]\", \"time\": \"2025-02-20T17:57:37.916Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074258122, 675596]\", \"time\": \"2025-02-20T17:57:38.122Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7ff31c05c0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074258166, 808051]\", \"time\": \"2025-02-20T17:57:38.166Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7fca7dda50d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074258189, 248331]\", \"time\": \"2025-02-20T17:57:38.189Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578302916987].\"}, {\"id\": \"[1740074258189, 965368]\", \"time\": \"2025-02-20T17:57:38.189Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074258190, 925420]\", \"time\": \"2025-02-20T17:57:38.190Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074258241, 862918]\", \"time\": \"2025-02-20T17:57:38.241Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1579078497939].\"}, {\"id\": \"[1740074258242, 802707]\", \"time\": \"2025-02-20T17:57:38.242Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074258242, 970652]\", \"time\": \"2025-02-20T17:57:38.242Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/15/S3A_SL_2_LST____20200115T085458_20200115T103557_20200116T153245_6059_053_378______LN2_O_NT_004.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074258494, 265867]\", \"time\": \"2025-02-20T17:57:38.494Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"}, {\"id\": \"[1740074258506, 959198]\", \"time\": \"2025-02-20T17:57:38.506Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@b8cdc27,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@3e385d7c),Vector(AccumulableInfo(458,None,Some(3461),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(0),None,false,true,None), AccumulableInfo(468,None,Some(1),None,false,true,None), AccumulableInfo(469,None,Some(0),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(375),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(0),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 3461), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 0), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 1), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 0), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 375), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 0), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\"}, {\"id\": \"[1740074259522, 178864]\", \"time\": \"2025-02-20T17:57:39.522Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7f3b280870d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074259562, 413503]\", \"time\": \"2025-02-20T17:57:39.562Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7f655360b0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074259670, 386280]\", \"time\": \"2025-02-20T17:57:39.670Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7efe104550d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074259693, 31706]\", \"time\": \"2025-02-20T17:57:39.693Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7f20d5b4d0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074259816, 67125]\", \"time\": \"2025-02-20T17:57:39.816Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1580724230572].\"}, {\"id\": \"[1740074259816, 944665]\", \"time\": \"2025-02-20T17:57:39.816Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074259817, 659456]\", \"time\": \"2025-02-20T17:57:39.817Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/03/S3B_SL_2_LST____20200203T100351_20200203T114450_20200204T175415_6059_035_122______LN2_O_NT_004.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074259819, 105317]\", \"time\": \"2025-02-20T17:57:39.819Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074259819, 194692]\", \"time\": \"2025-02-20T17:57:39.819Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074259819, 537512]\", \"time\": \"2025-02-20T17:57:39.819Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577957541006].\"}, {\"id\": \"[1740074259828, 240976]\", \"time\": \"2025-02-20T17:57:39.828Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578514195022].\"}, {\"id\": \"[1740074259828, 467333]\", \"time\": \"2025-02-20T17:57:39.828Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/08/S3A_SL_2_LST____20200108T200955_20200108T201255_20210121T145509_0179_053_285_0720_LR1_R_NT_004.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074259828, 576836]\", \"time\": \"2025-02-20T17:57:39.828Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074259931, 131222]\", \"time\": \"2025-02-20T17:57:39.931Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578597447268].\"}, {\"id\": \"[1740074259931, 299582]\", \"time\": \"2025-02-20T17:57:39.931Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074259932, 489714]\", \"time\": \"2025-02-20T17:57:39.932Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074260259, 761176]\", \"time\": \"2025-02-20T17:57:40.259Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/08/S3A_SL_2_LST____20200108T200955_20200108T201255_20210121T145509_0179_053_285_0720_LR1_R_NT_004.SEN3/geodetic_tx.nc\"}, {\"id\": \"[1740074260259, 773705]\", \"time\": \"2025-02-20T17:57:40.259Z\", \"level\": \"info\", \"message\": \"bbox_original=[nan, nan, nan, nan] source_coordinates=array([[14.980168, 50.91207 ],\\n       [14.966739, 50.908527],\\n       [14.97621 , 50.921303],\\n       ...,\\n       [13.853938, 52.04209 ],\\n       [13.840382, 52.038013],\\n       [13.84907 , 52.04998 ]], dtype=float32)\"}, {\"id\": \"[1740074260407, 22658]\", \"time\": \"2025-02-20T17:57:40.407Z\", \"level\": \"info\", \"message\": \"Creating LUT with shape (129, 129, 2)\"}, {\"id\": \"[1740074260407, 508743]\", \"time\": \"2025-02-20T17:57:40.407Z\", \"level\": \"info\", \"message\": \"Reprojecting SL_2_LST___\"}, {\"id\": \"[1740074260416, 2953]\", \"time\": \"2025-02-20T17:57:40.416Z\", \"level\": \"info\", \"message\": \"Creating LUT with shape (250, 249, 2)\"}, {\"id\": \"[1740074260433, 366942]\", \"time\": \"2025-02-20T17:57:40.433Z\", \"level\": \"info\", \"message\": \" Reprojecting LST_in:LST\"}, {\"id\": \"[1740074260433, 510477]\", \"time\": \"2025-02-20T17:57:40.433Z\", \"level\": \"debug\", \"message\": \"Reading LST from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/08/S3A_SL_2_LST____20200108T200955_20200108T201255_20210121T145509_0179_053_285_0720_LR1_R_NT_004.SEN3/LST_in.nc\"}, {\"id\": \"[1740074260655, 23243]\", \"time\": \"2025-02-20T17:57:40.655Z\", \"level\": \"info\", \"message\": \" Split (1, 129, 129) in tiles of 128\"}, {\"id\": \"[1740074260655, 24373]\", \"time\": \"2025-02-20T17:57:40.655Z\", \"level\": \"info\", \"message\": \" Create Tile for key SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 1, 8, 20, 9)) from (1, 128, 128)\"}, {\"id\": \"[1740074260655, 693006]\", \"time\": \"2025-02-20T17:57:40.655Z\", \"level\": \"info\", \"message\": \"Done reprojecting SL_2_LST___\"}, {\"id\": \"[1740074260655, 832483]\", \"time\": \"2025-02-20T17:57:40.655Z\", \"level\": \"info\", \"message\": \" Layout extent split in 1 tiles\"}, {\"id\": \"[1740074261780, 537651]\", \"time\": \"2025-02-20T17:57:41.780Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\"}, {\"id\": \"[1740074261791, 397955]\", \"time\": \"2025-02-20T17:57:41.791Z\", \"level\": \"warning\", \"message\": \"Lost task 8.0 in stage 18.0 (TID 139) (10.42.16.189 executor 4): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}, {\"id\": \"[1740074261793, 150681]\", \"time\": \"2025-02-20T17:57:41.793Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@2f3d831a,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@73f9600e),Vector(AccumulableInfo(458,None,Some(5399),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(380),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(2),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 5399), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 380), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 2), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(281273632, 87342960, 32768, 0, 25829, 0, 58597, 0, 4263247, 0, 6465241088, 717463552, 2014699520, 990191616, 0, 0, 0, 0, 3, 215, 215))\"}, {\"id\": \"[1740074261906, 669244]\", \"time\": \"2025-02-20T17:57:41.906Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074261906, 879443]\", \"time\": \"2025-02-20T17:57:41.906Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578993668796].\"}, {\"id\": \"[1740074261907, 3059]\", \"time\": \"2025-02-20T17:57:41.907Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074262202, 168131]\", \"time\": \"2025-02-20T17:57:42.202Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"}, {\"id\": \"[1740074262216, 402921]\", \"time\": \"2025-02-20T17:57:42.216Z\", \"level\": \"warning\", \"message\": \"Lost task 2.2 in stage 18.0 (TID 137) (10.42.231.60 executor 3): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}, {\"id\": \"[1740074262219, 59095]\", \"time\": \"2025-02-20T17:57:42.219Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@1e79e7b2,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@62d69abc),Vector(AccumulableInfo(458,None,Some(5822),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(380),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(3),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 5822), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 380), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 3), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(427629528, 90979936, 32768, 0, 25829, 0, 58597, 0, 4271663, 0, 8238493696, 797495296, 366895104, 86925312, 0, 0, 0, 0, 3, 246, 246))\"}, {\"id\": \"[1740074262726, 501320]\", \"time\": \"2025-02-20T17:57:42.726Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/15/S3A_SL_2_LST____20200115T085458_20200115T103557_20200116T153245_6059_053_378______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"}, {\"id\": \"[1740074262747, 875771]\", \"time\": \"2025-02-20T17:57:42.747Z\", \"level\": \"warning\", \"message\": \"Lost task 9.0 in stage 18.0 (TID 140) (10.42.243.240 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/15/S3A_SL_2_LST____20200115T085458_20200115T103557_20200116T153245_6059_053_378______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}, {\"id\": \"[1740074262757, 388524]\", \"time\": \"2025-02-20T17:57:42.757Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/15/S3A_SL_2_LST____20200115T085458_20200115T103557_20200116T153245_6059_053_378______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@21b0f0af,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/15/S3A_SL_2_LST____20200115T085458_20200115T103557_20200116T153245_6059_053_378______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@19f10d87),Vector(AccumulableInfo(458,None,Some(6346),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(380),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(10),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 6346), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 380), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 10), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(474706632, 108645096, 32768, 0, 25829, 0, 58597, 0, 8475290, 0, 8548982784, 1313402880, 2500182016, 1787789312, 0, 0, 1, 28, 3, 222, 250))\"}, {\"id\": \"[1740074263145, 467017]\", \"time\": \"2025-02-20T17:57:43.145Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7f3ec140a0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074263147, 223643]\", \"time\": \"2025-02-20T17:57:43.147Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577903007981].\"}, {\"id\": \"[1740074263147, 653057]\", \"time\": \"2025-02-20T17:57:43.147Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074263147, 677660]\", \"time\": \"2025-02-20T17:57:43.147Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074263181, 839332]\", \"time\": \"2025-02-20T17:57:43.181Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\"}, {\"id\": \"[1740074263222, 238157]\", \"time\": \"2025-02-20T17:57:43.222Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@48e43d7c,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@1eb14da6),Vector(AccumulableInfo(458,None,Some(6766),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(461,None,Some(66),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(381),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(11),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 6766), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 461, name: Some(internal.metrics.jvmGCTime), value: 66), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 381), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 11), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\"}, {\"id\": \"[1740074263433, 270387]\", \"time\": \"2025-02-20T17:57:43.433Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\"}, {\"id\": \"[1740074263470, 472908]\", \"time\": \"2025-02-20T17:57:43.470Z\", \"level\": \"warning\", \"message\": \"Lost task 0.2 in stage 18.0 (TID 136) (10.42.90.120 executor 7): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}, {\"id\": \"[1740074263472, 106418]\", \"time\": \"2025-02-20T17:57:43.472Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@38a2f357,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@29ae5cf1),Vector(AccumulableInfo(458,None,Some(7009),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(461,None,Some(63),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(379),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(12),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 7009), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 461, name: Some(internal.metrics.jvmGCTime), value: 63), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 379), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 12), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\"}, {\"id\": \"[1740074263794, 508451]\", \"time\": \"2025-02-20T17:57:43.794Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7ff8ebb8d0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074263898, 206794]\", \"time\": \"2025-02-20T17:57:43.898Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7ff31c05c0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074264054, 440903]\", \"time\": \"2025-02-20T17:57:44.054Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1581670115362].\"}, {\"id\": \"[1740074264054, 831813]\", \"time\": \"2025-02-20T17:57:44.054Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074264055, 682564]\", \"time\": \"2025-02-20T17:57:44.055Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/14/S3B_SL_2_LST____20200214T084835_20200214T085135_20200822T174230_0180_035_278_2160_LR1_R_NT_004.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074264142, 377627]\", \"time\": \"2025-02-20T17:57:44.142Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1579457855543].\"}, {\"id\": \"[1740074264143, 615278]\", \"time\": \"2025-02-20T17:57:44.143Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/19/S3B_SL_2_LST____20200119T181736_20200119T195835_20200121T020758_6059_034_298______LN2_O_NT_004.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074264143, 886165]\", \"time\": \"2025-02-20T17:57:44.143Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074264322, 77061]\", \"time\": \"2025-02-20T17:57:44.322Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7efe104550d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074264384, 121210]\", \"time\": \"2025-02-20T17:57:44.384Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1579078497939].\"}, {\"id\": \"[1740074264384, 559097]\", \"time\": \"2025-02-20T17:57:44.384Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074264384, 949493]\", \"time\": \"2025-02-20T17:57:44.384Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/15/S3A_SL_2_LST____20200115T085458_20200115T103557_20200116T153245_6059_053_378______LN2_O_NT_004.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074264504, 96395]\", \"time\": \"2025-02-20T17:57:44.504Z\", \"level\": \"info\", \"message\": \"bbox_original=[nan, nan, nan, nan] source_coordinates=array([[14.976556, 52.04619 ],\\n       [14.976556, 52.04619 ],\\n       [14.856339, 52.04986 ],\\n       ...,\\n       [14.204908, 50.908207],\\n       [14.219062, 50.907364],\\n       [14.062057, 50.907753]], dtype=float32)\"}, {\"id\": \"[1740074264504, 594671]\", \"time\": \"2025-02-20T17:57:44.504Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/14/S3B_SL_2_LST____20200214T084835_20200214T085135_20200822T174230_0180_035_278_2160_LR1_R_NT_004.SEN3/geodetic_tx.nc\"}, {\"id\": \"[1740074264520, 149068]\", \"time\": \"2025-02-20T17:57:44.520Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/03/S3B_SL_2_LST____20200203T100351_20200203T114450_20200204T175415_6059_035_122______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\"}, {\"id\": \"[1740074264538, 599985]\", \"time\": \"2025-02-20T17:57:44.538Z\", \"level\": \"warning\", \"message\": \"Lost task 11.0 in stage 18.0 (TID 142) (10.42.247.49 executor 2): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/03/S3B_SL_2_LST____20200203T100351_20200203T114450_20200204T175415_6059_035_122______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}, {\"id\": \"[1740074264547, 27862]\", \"time\": \"2025-02-20T17:57:44.547Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/03/S3B_SL_2_LST____20200203T100351_20200203T114450_20200204T175415_6059_035_122______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@40c89b65,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/03/S3B_SL_2_LST____20200203T100351_20200203T114450_20200204T175415_6059_035_122______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@548022a7),Vector(AccumulableInfo(458,None,Some(6020),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(461,None,Some(17),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(0),None,false,true,None), AccumulableInfo(468,None,Some(1),None,false,true,None), AccumulableInfo(469,None,Some(0),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(379),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(0),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 6020), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 461, name: Some(internal.metrics.jvmGCTime), value: 17), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 0), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 1), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 0), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 379), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 0), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\"}, {\"id\": \"[1740074264639, 132209]\", \"time\": \"2025-02-20T17:57:44.639Z\", \"level\": \"info\", \"message\": \"Reprojecting SL_2_LST___\"}, {\"id\": \"[1740074264640, 304015]\", \"time\": \"2025-02-20T17:57:44.640Z\", \"level\": \"info\", \"message\": \"Creating LUT with shape (129, 129, 2)\"}, {\"id\": \"[1740074264650, 57681]\", \"time\": \"2025-02-20T17:57:44.650Z\", \"level\": \"info\", \"message\": \"Creating LUT with shape (250, 249, 2)\"}, {\"id\": \"[1740074264671, 828596]\", \"time\": \"2025-02-20T17:57:44.671Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7fca7dda50d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074264674, 273028]\", \"time\": \"2025-02-20T17:57:44.674Z\", \"level\": \"debug\", \"message\": \"Reading LST from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/14/S3B_SL_2_LST____20200214T084835_20200214T085135_20200822T174230_0180_035_278_2160_LR1_R_NT_004.SEN3/LST_in.nc\"}, {\"id\": \"[1740074264674, 658129]\", \"time\": \"2025-02-20T17:57:44.674Z\", \"level\": \"info\", \"message\": \" Reprojecting LST_in:LST\"}, {\"id\": \"[1740074264675, 102355]\", \"time\": \"2025-02-20T17:57:44.675Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578302916987].\"}, {\"id\": \"[1740074264675, 234527]\", \"time\": \"2025-02-20T17:57:44.675Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074264676, 551937]\", \"time\": \"2025-02-20T17:57:44.676Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074264744, 80845]\", \"time\": \"2025-02-20T17:57:44.744Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7f3b280870d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074264822, 48332]\", \"time\": \"2025-02-20T17:57:44.822Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074264822, 83897]\", \"time\": \"2025-02-20T17:57:44.822Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074264822, 230150]\", \"time\": \"2025-02-20T17:57:44.822Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578597447268].\"}, {\"id\": \"[1740074264873, 64740]\", \"time\": \"2025-02-20T17:57:44.873Z\", \"level\": \"info\", \"message\": \" Layout extent split in 1 tiles\"}, {\"id\": \"[1740074264873, 469027]\", \"time\": \"2025-02-20T17:57:44.873Z\", \"level\": \"info\", \"message\": \"Done reprojecting SL_2_LST___\"}, {\"id\": \"[1740074264873, 724448]\", \"time\": \"2025-02-20T17:57:44.873Z\", \"level\": \"info\", \"message\": \" Create Tile for key SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 2, 14, 8, 48)) from (1, 128, 128)\"}, {\"id\": \"[1740074264873, 750291]\", \"time\": \"2025-02-20T17:57:44.873Z\", \"level\": \"info\", \"message\": \" Split (1, 129, 129) in tiles of 128\"}, {\"id\": \"[1740074264879, 131876]\", \"time\": \"2025-02-20T17:57:44.879Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\"}, {\"id\": \"[1740074264919, 429559]\", \"time\": \"2025-02-20T17:57:44.919Z\", \"level\": \"warning\", \"message\": \"Lost task 8.1 in stage 18.0 (TID 144) (10.42.146.92 executor 6): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}, {\"id\": \"[1740074264937, 400057]\", \"time\": \"2025-02-20T17:57:44.937Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@7b975b2b,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@2005c97c),Vector(AccumulableInfo(458,None,Some(3088),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(380),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(9),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(15),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 3088), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 380), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 9), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 15), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\"}, {\"id\": \"[1740074266041, 223917]\", \"time\": \"2025-02-20T17:57:46.041Z\", \"level\": \"debug\", \"message\": \"Overriding sys.excepthook with <function _sys_excepthook at 0x7f20d5b4d0d0> (was <built-in function excepthook>)\"}, {\"id\": \"[1740074266042, 263614]\", \"time\": \"2025-02-20T17:57:46.042Z\", \"level\": \"info\", \"message\": \" Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577957541006].\"}, {\"id\": \"[1740074266042, 820846]\", \"time\": \"2025-02-20T17:57:46.042Z\", \"level\": \"info\", \"message\": \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"}, {\"id\": \"[1740074266043, 108079]\", \"time\": \"2025-02-20T17:57:46.043Z\", \"level\": \"debug\", \"message\": \"Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3/geodetic_in.nc\"}, {\"id\": \"[1740074266317, 137870]\", \"time\": \"2025-02-20T17:57:46.317Z\", \"level\": \"error\", \"message\": \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"}, {\"id\": \"[1740074266338, 921628]\", \"time\": \"2025-02-20T17:57:46.338Z\", \"level\": \"warning\", \"message\": \"Lost task 1.3 in stage 18.0 (TID 143) (10.42.16.189 executor 4): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}, {\"id\": \"[1740074266340, 929416]\", \"time\": \"2025-02-20T17:57:46.340Z\", \"level\": \"error\", \"message\": \"Task 1 in stage 18.0 failed 4 times; aborting job\"}, {\"id\": \"[1740074266353, 858226]\", \"time\": \"2025-02-20T17:57:46.353Z\", \"level\": \"warning\", \"message\": \"Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@24927daa,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@7152f685),Vector(AccumulableInfo(458,None,Some(4516),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(375),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(19),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(24),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 4516), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 375), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 19), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 24), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\"}, {\"id\": \"[1740074266376, 404048]\", \"time\": \"2025-02-20T17:57:46.376Z\", \"level\": \"error\", \"message\": \"Stage error: Job aborted due to stage failure: Task 1 in stage 18.0 failed 4 times, most recent failure: Lost task 1.3 in stage 18.0 (TID 143) (10.42.16.189 executor 4): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\\nDriver stacktrace:\"}, {\"id\": \"[1740074266576, 899488]\", \"time\": \"2025-02-20T17:57:46.576Z\", \"level\": \"info\", \"message\": \"input asset hrefs: {}\"}, {\"id\": \"[1740074266580, 929631]\", \"time\": \"2025-02-20T17:57:46.580Z\", \"level\": \"info\", \"message\": \"output asset hrefs: {}\"}, {\"id\": \"[1740074266633, 804786]\", \"time\": \"2025-02-20T17:57:46.633Z\", \"level\": \"info\", \"message\": \"wrote metadata to /batch_jobs/j-250220175546475684630774e1358c51/job_metadata.json\"}, {\"id\": \"[1740074266851, 753431]\", \"time\": \"2025-02-20T17:57:46.851Z\", \"level\": \"info\", \"message\": \"Summary of the executed stages with the Logs of the longest stages:\"}, {\"id\": \"[1740074266852, 460420]\", \"time\": \"2025-02-20T17:57:46.852Z\", \"level\": \"info\", \"message\": \"Total number of stages: 14\"}, {\"id\": \"[1740074266852, 722178]\", \"time\": \"2025-02-20T17:57:46.852Z\", \"level\": \"info\", \"message\": \"Total stage runtime: 1 minutes\"}, {\"id\": \"[1740074266852, 801728]\", \"time\": \"2025-02-20T17:57:46.852Z\", \"level\": \"info\", \"message\": \"Total executor allocation time: 232009898 minutes\"}, {\"id\": \"[1740074266853, 677398]\", \"time\": \"2025-02-20T17:57:46.853Z\", \"level\": \"warning\", \"message\": \"A part of the process graph failed, and will be retried, the reason was: \\\"Job aborted due to stage failure: Task 1 in stage 18.0 failed 4 times, most recent failure: Lost task 1.3 in stage 18.0 (TID 143) (10.42.16.189 executor 4): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 693, in __array__\\n    self._ensure_cached()\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 70, in __array__\\n    return self.func(self.array)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\\\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\\\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\\\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \\\"src/netCDF4/_netCDF4.pyx\\\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1247, in main\\n    process()\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\\\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\\\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \\\"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\\\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/epsel.py\\\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\\nDriver stacktrace:\\\"\\nYour job may still complete if the failure was caused by a transient error, but will take more time. A common cause of transient errors is too little executor memory (overhead). Too low executor-memory can be seen by a high 'garbage collection' time, which was: 0.0 seconds.\\n\"}, {\"id\": \"[1740074268613, 252849]\", \"time\": \"2025-02-20T17:57:48.613Z\", \"level\": \"info\", \"message\": \"Starting batch job os.getpid()=79: fail 2025-02-20 17:57:48.613108, elapsed 0:01:24.809122\"}, {\"id\": \"[1740074268620, 46728]\", \"time\": \"2025-02-20T17:57:48.620Z\", \"level\": \"error\", \"message\": \"OpenEO batch job failed: Exception during Spark execution: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\\\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\\\"float32\\\")\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\\\", line 1433, in astype\\n    return apply_ufunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\\\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 361, in data\\n    return self.values\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\\\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \\\"/opt/openeo/lib/python3.8/site-packages/xarray/core/variabl...\"}]}</script>\n",
       "    </openeo-logs>\n",
       "    "
      ],
      "text/plain": [
       "[{'id': '[1740074183804, 429565]',\n",
       "  'time': '2025-02-20T17:56:23.804Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting batch job os.getpid()=79: start 2025-02-20 17:56:23.803986'},\n",
       " {'id': '[1740074184872, 102543]',\n",
       "  'time': '2025-02-20T17:56:24.872Z',\n",
       "  'level': 'info',\n",
       "  'message': \"Loaded config config_id='os_creodias_openeo_k8s_prod' from config_path='/opt/backend_config/backendconfig.py' (reason='lazy_load')\"},\n",
       " {'id': '[1740074185858, 235995]',\n",
       "  'time': '2025-02-20T17:56:25.858Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Logging initialized @9739ms to org.sparkproject.jetty.util.log.Slf4jLog'},\n",
       " {'id': '[1740074197281, 669993]',\n",
       "  'time': '2025-02-20T17:56:37.281Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Job spec: {\\n \"process_graph\": {\\n  \"apply1\": {\\n   \"process_id\": \"apply\",\\n   \"arguments\": {\\n    \"process\": {\\n     \"process_graph\": {\\n      \"gte1\": {\\n       \"result\": true,\\n       \"process_id\": \"gte\",\\n       \"arguments\": {\\n        \"x\": {\\n         \"from_parameter\": \"x\"\\n        },\\n        \"y\": 16384\\n       }\\n      }\\n     }\\n    },\\n    \"data\": {\\n     \"from_node\": \"loadcollection2\"\\n    }\\n   }\\n  },\\n  \"loadcollection1\": {\\n   \"process_id\": \"load_collection\",\\n   \"arguments\": {\\n    \"temporal_extent\": [\\n     \"2020-01-01\",\\n     \"2020-03-01\"\\n    ],\\n    \"spatial_extent\": {\\n     \"east\": 14.3,\\n     \"south\": 51.7,\\n     \"north\": 52.05,\\n     \"west\": 13.84\\n    },\\n    \"id\": \"SENTINEL3_SLSTR_L2_LST\",\\n    \"bands\": [\\n     \"LST\"\\n    ]\\n   }\\n  },\\n  \"mask1\": {\\n   \"process_id\": \"mask\",\\n   \"arguments\": {\\n    \"data\": {\\n     \"from_node\": \"loadcollection1\"\\n    },\\n    \"mask\": {\\n     \"from_node\": \"apply1\"\\n    }\\n   }\\n  },\\n  \"saveresult1\": {\\n   \"result\": true,\\n   \"process_id\": \"save_result\",\\n   \"arguments\": {\\n    \"data\": {\\n     \"from_node\": \"mask1\"\\n    },\\n    \"format\": \"netCDF\",\\n    \"options\": {}\\n   }\\n  },\\n  \"loadcollection2\": {\\n   \"process_id\": \"load_collection\",\\n   \"arguments\": {\\n    \"temporal_extent\": [\\n     \"2020-01-01\",\\n     \"2020-03-01\"\\n    ],\\n    \"spatial_extent\": {\\n     \"east\": 14.3,\\n     \"south\": 51.7,\\n     \"north\": 52.05,\\n     \"west\": 13.84\\n    },\\n    \"id\": \"SENTINEL3_SLSTR_L2_LST\",\\n    \"bands\": [\\n     \"confidence_in\"\\n    ]\\n   }\\n  }\\n },\\n \"job_options\": {\\n  \"log_level\": \"info\"\\n }\\n}'},\n",
       " {'id': '[1740074199280, 777481]',\n",
       "  'time': '2025-02-20T17:56:39.280Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'No elastic_job_registry given to GeoPySparkBackendImplementation, creating one'},\n",
       " {'id': '[1740074199422, 99089]',\n",
       "  'time': '2025-02-20T17:56:39.422Z',\n",
       "  'level': 'info',\n",
       "  'message': \"Doing 'client_credentials' token request 'https://sso.terrascope.be/auth/realms/terrascope/protocol/openid-connect/token' with post data fields ['grant_type', 'client_id', 'client_secret', 'scope'] (client_id 'openeo-elastic-job-registry')\"},\n",
       " {'id': '[1740074199841, 343263]',\n",
       "  'time': '2025-02-20T17:56:39.841Z',\n",
       "  'level': 'info',\n",
       "  'message': \"EJR health check {'status': 'ok', 'info': {'elasticsearch-ping': {'status': 'up'}, 'elasticsearch-health': {'status': 'up'}, 'auth': {'status': 'up', 'state': 'ok'}}, 'error': {}, 'details': {}}\"},\n",
       " {'id': '[1740074200914, 457019]',\n",
       "  'time': '2025-02-20T17:56:40.914Z',\n",
       "  'level': 'info',\n",
       "  'message': \"Loaded config config_id='os_creodias_openeo_k8s_prod' from config_path='/opt/backend_config/backendconfig.py' (reason='lazy_load')\"},\n",
       " {'id': '[1740074200914, 697425]',\n",
       "  'time': '2025-02-20T17:56:40.914Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Correlation id: j-250220175546475684630774e1358c51'},\n",
       " {'id': '[1740074200915, 757908]',\n",
       "  'time': '2025-02-20T17:56:40.915Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Doing dry run'},\n",
       " {'id': '[1740074200917, 156002]',\n",
       "  'time': '2025-02-20T17:56:40.917Z',\n",
       "  'level': 'info',\n",
       "  'message': \"Dry run extracted these source constraints: [(('load_collection', ('SENTINEL3_SLSTR_L2_LST', (('productType', (('eq', 'SL_2_LST___'),)),), ('confidence_in',))), {'temporal_extent': ('2020-01-01', '2020-03-01'), 'spatial_extent': {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'}, 'bands': ['confidence_in'], 'properties': {'productType': {'process_graph': {'eq1': {'process_id': 'eq', 'arguments': {'x': {'from_parameter': 'value'}, 'y': 'SL_2_LST___'}, 'result': True}}}}}), (('load_collection', ('SENTINEL3_SLSTR_L2_LST', (('productType', (('eq', 'SL_2_LST___'),)),), ('LST',))), {'temporal_extent': ('2020-01-01', '2020-03-01'), 'spatial_extent': {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'}, 'bands': ['LST'], 'properties': {'productType': {'process_graph': {'eq1': {'process_id': 'eq', 'arguments': {'x': {'from_parameter': 'value'}, 'y': 'SL_2_LST___'}, 'result': True}}}}})]\"},\n",
       " {'id': '[1740074200917, 477904]',\n",
       "  'time': '2025-02-20T17:56:40.917Z',\n",
       "  'level': 'info',\n",
       "  'message': 'load_collection: start 2025-02-20 17:56:40.917252'},\n",
       " {'id': '[1740074200937, 773216]',\n",
       "  'time': '2025-02-20T17:56:40.937Z',\n",
       "  'level': 'info',\n",
       "  'message': \"load_collection: Creating raster datacube for SENTINEL3_SLSTR_L2_LST with arguments {'temporal_extent': ('2020-01-01', '2020-03-01'), 'spatial_extent': {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'}, 'global_extent': {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'}, 'bands': ['confidence_in'], 'properties': {'productType': {'process_graph': {'eq1': {'process_id': 'eq', 'arguments': {'x': {'from_parameter': 'value'}, 'y': 'SL_2_LST___'}, 'result': True}}}}, 'aggregate_spatial_geometries': None, 'sar_backscatter': None, 'process_types': set(), 'custom_mask': {}, 'data_mask': None, 'target_crs': None, 'target_resolution': None, 'resample_method': 'near', 'pixel_buffer': None}, environment: {'vault_token': None, 'sentinel_hub_client_alias': None, 'max_soft_errors_ratio': 0.1, 'dependencies': [], 'pyramid_levels': 'highest', 'require_bounds': True, 'correlation_id': 'j-250220175546475684630774e1358c51', 'user': User('d60dac41-2704-47b5-8f58-23f58c3b8f8e', None)}\"},\n",
       " {'id': '[1740074200938, 825203]',\n",
       "  'time': '2025-02-20T17:56:40.938Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Detected process types:set()'},\n",
       " {'id': '[1740074200938, 902931]',\n",
       "  'time': '2025-02-20T17:56:40.938Z',\n",
       "  'level': 'info',\n",
       "  'message': \"Correlation ID is 'j-250220175546475684630774e1358c51'\"},\n",
       " {'id': '[1740074207627, 38722]',\n",
       "  'time': '2025-02-20T17:56:47.627Z',\n",
       "  'level': 'info',\n",
       "  'message': 'https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel3/search.json?box=13.84%2C51.7%2C14.3%2C52.05&page=1&maxRecords=1000&status=ONLINE&dataset=ESA-DATASET&productType=SL_2_LST___&startDate=2020-01-01T00%3A00%3A00Z&completionDate=2020-02-29T23%3A59%3A59.999999999Z returned 200'},\n",
       " {'id': '[1740074211655, 45837]',\n",
       "  'time': '2025-02-20T17:56:51.655Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 0 - mapValues at ClipToGrid.scala:92. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074216731, 423045]',\n",
       "  'time': '2025-02-20T17:56:56.731Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 1 - distinct at FileRDDFactory.scala:100. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074216843, 20501]',\n",
       "  'time': '2025-02-20T17:56:56.843Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Stage 1 contains a task of very large size (1057 KiB). The maximum recommended task size is 1000 KiB.'},\n",
       " {'id': '[1740074217725, 350244]',\n",
       "  'time': '2025-02-20T17:56:57.725Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 2 - collect at FileRDDFactory.scala:100. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074218112, 460944]',\n",
       "  'time': '2025-02-20T17:56:58.112Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Convert JavaObject id=o1919 to geopyspark.Metadata'},\n",
       " {'id': '[1740074218236, 724342]',\n",
       "  'time': '2025-02-20T17:56:58.236Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 4 - filter at FileRDDFactory.scala:94. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074218255, 859655]',\n",
       "  'time': '2025-02-20T17:56:58.255Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Stage 4 contains a task of very large size (1057 KiB). The maximum recommended task size is 1000 KiB.'},\n",
       " {'id': '[1740074218776, 226460]',\n",
       "  'time': '2025-02-20T17:56:58.776Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 5 - groupByKey at /opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py:138. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074221753, 784120]',\n",
       "  'time': '2025-02-20T17:57:01.753Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 6 - collect at /opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py:140. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074222954, 287188]',\n",
       "  'time': '2025-02-20T17:57:02.954Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Constructing TiledRasterLayer from numpy rdd, with metadata Metadata(Bounds(minKey=SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 1, 1, 0, 0)), maxKey=SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 2, 29, 23, 59))), float32, nan, +proj=longlat +datum=WGS84 +no_defs , Extent(xmin=13.84, ymin=51.7, xmax=14.3, ymax=52.05), TileLayout(layoutCols=1, layoutRows=1, tileCols=128, tileRows=128), LayoutDefinition(extent=Extent(xmin=13.84, ymin=50.90714285714291, xmax=14.982857142857087, ymax=52.05), tileLayout=TileLayout(layoutCols=1, layoutRows=1, tileCols=128, tileRows=128)))'},\n",
       " {'id': '[1740074223288, 129117]',\n",
       "  'time': '2025-02-20T17:57:03.288Z',\n",
       "  'level': 'info',\n",
       "  'message': 'load_collection: end 2025-02-20 17:57:03.287514, elapsed 0:00:22.370262'},\n",
       " {'id': '[1740074223397, 804054]',\n",
       "  'time': '2025-02-20T17:57:03.397Z',\n",
       "  'level': 'info',\n",
       "  'message': 'load_collection: start 2025-02-20 17:57:03.396822'},\n",
       " {'id': '[1740074223419, 361437]',\n",
       "  'time': '2025-02-20T17:57:03.419Z',\n",
       "  'level': 'info',\n",
       "  'message': \"load_collection: Creating raster datacube for SENTINEL3_SLSTR_L2_LST with arguments {'temporal_extent': ('2020-01-01', '2020-03-01'), 'spatial_extent': {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'}, 'global_extent': {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'}, 'bands': ['LST'], 'properties': {'productType': {'process_graph': {'eq1': {'process_id': 'eq', 'arguments': {'x': {'from_parameter': 'value'}, 'y': 'SL_2_LST___'}, 'result': True}}}}, 'aggregate_spatial_geometries': None, 'sar_backscatter': None, 'process_types': set(), 'custom_mask': {}, 'data_mask': <openeogeotrellis.geopysparkdatacube.GeopysparkDataCube object at 0x7f01b99ed280>, 'target_crs': None, 'target_resolution': None, 'resample_method': 'near', 'pixel_buffer': None}, environment: {'vault_token': None, 'sentinel_hub_client_alias': None, 'max_soft_errors_ratio': 0.1, 'dependencies': [], 'pyramid_levels': 'highest', 'require_bounds': True, 'correlation_id': 'j-250220175546475684630774e1358c51', 'user': User('d60dac41-2704-47b5-8f58-23f58c3b8f8e', None)}\"},\n",
       " {'id': '[1740074223420, 84067]',\n",
       "  'time': '2025-02-20T17:57:03.420Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Detected process types:set()'},\n",
       " {'id': '[1740074223420, 659552]',\n",
       "  'time': '2025-02-20T17:57:03.420Z',\n",
       "  'level': 'info',\n",
       "  'message': \"Correlation ID is 'j-250220175546475684630774e1358c51'\"},\n",
       " {'id': '[1740074228614, 207118]',\n",
       "  'time': '2025-02-20T17:57:08.614Z',\n",
       "  'level': 'info',\n",
       "  'message': 'https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel3/search.json?box=13.84%2C51.7%2C14.3%2C52.05&page=1&maxRecords=1000&status=ONLINE&dataset=ESA-DATASET&productType=SL_2_LST___&startDate=2020-01-01T00%3A00%3A00Z&completionDate=2020-02-29T23%3A59%3A59.999999999Z returned 200'},\n",
       " {'id': '[1740074229181, 955338]',\n",
       "  'time': '2025-02-20T17:57:09.181Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 7 - mapValues at ClipToGrid.scala:92. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074231304, 111573]',\n",
       "  'time': '2025-02-20T17:57:11.304Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 8 - distinct at FileRDDFactory.scala:100. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074231894, 517126]',\n",
       "  'time': '2025-02-20T17:57:11.894Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 9 - collect at FileRDDFactory.scala:100. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074232211, 459885]',\n",
       "  'time': '2025-02-20T17:57:12.211Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Convert JavaObject id=o2032 to geopyspark.Metadata'},\n",
       " {'id': '[1740074232252, 348718]',\n",
       "  'time': '2025-02-20T17:57:12.252Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 11 - filter at FileRDDFactory.scala:94. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074232566, 522386]',\n",
       "  'time': '2025-02-20T17:57:12.566Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 12 - groupByKey at /opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py:138. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074234779, 735154]',\n",
       "  'time': '2025-02-20T17:57:14.779Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 13 - collect at /opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py:140. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074235907, 279390]',\n",
       "  'time': '2025-02-20T17:57:15.907Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Constructing TiledRasterLayer from numpy rdd, with metadata Metadata(Bounds(minKey=SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 1, 1, 0, 0)), maxKey=SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 2, 29, 23, 59))), float32, nan, +proj=longlat +datum=WGS84 +no_defs , Extent(xmin=13.84, ymin=51.7, xmax=14.3, ymax=52.05), TileLayout(layoutCols=1, layoutRows=1, tileCols=128, tileRows=128), LayoutDefinition(extent=Extent(xmin=13.84, ymin=50.90714285714291, xmax=14.982857142857087, ymax=52.05), tileLayout=TileLayout(layoutCols=1, layoutRows=1, tileCols=128, tileRows=128)))'},\n",
       " {'id': '[1740074235940, 422572]',\n",
       "  'time': '2025-02-20T17:57:15.940Z',\n",
       "  'level': 'info',\n",
       "  'message': 'load_collection: end 2025-02-20 17:57:15.940109, elapsed 0:00:12.543287'},\n",
       " {'id': '[1740074235941, 163204]',\n",
       "  'time': '2025-02-20T17:57:15.941Z',\n",
       "  'level': 'info',\n",
       "  'message': \"Evaluated process graph, result (type <class 'openeo_driver.save_result.ImageCollectionResult'>): <openeo_driver.save_result.ImageCollectionResult object at 0x7f01b99edcd0>\"},\n",
       " {'id': '[1740074235941, 664722]',\n",
       "  'time': '2025-02-20T17:57:15.941Z',\n",
       "  'level': 'info',\n",
       "  'message': \"Extracting result metadata from <DryRunDataTracer (traces: [<DataSource#139646656371712('load_collection', ('SENTINEL3_SLSTR_L2_LST', {'productType': {'eq': 'SL_2_LST___'}}, ['confidence_in']))>, <DataTrace#139645765505168(#139646656371712, temporal_extent, ('2020-01-01', '2020-03-01'))>, <DataTrace#139646656410864(#139645765505168, spatial_extent, {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'})>, <DataTrace#139646656410544(#139646656410864, bands, ['confidence_in'])>, <DataTrace#139646656410304(#139646656410544, properties, {'productType': {'process_graph': {'eq1': {'process_id': 'eq', 'arguments': {'x': {'from_parameter': 'value'}, 'y': 'SL_2_LST___'}, 'result': True}}}})>, <DataTrace#139646656410464(#139646656410304, apply, {})>, <DataSource#139645764225344('load_collection', ('SENTINEL3_SLSTR_L2_LST', {'productType': {'eq': 'SL_2_LST___'}}, ['LST']))>, <DataTrace#139646656410704(#139645764225344, temporal_extent, ('2020-01-01', '2020-03-01'))>, <DataTrace#139645385357248(#139646656410704, spatial_extent, {'west': 13.84, 'south': 51.7, 'east': 14.3, 'north': 52.05, 'crs': 'EPSG:4326'})>, <DataTrace#139645385357328(#139645385357248, bands, ['LST'])>, <DataTrace#139645385357408(#139645385357328, properties, {'productType': {'process_graph': {'eq1': {'process_id': 'eq', 'arguments': {'x': {'from_parameter': 'value'}, 'y': 'SL_2_LST___'}, 'result': True}}}})>, <DataTrace#139645385357488(#139646656410464, resample_cube_spatial, {'target': <openeo_driver.dry_run.DryRunDataCube object at 0x7f01d02b3d30>, 'method': 'near'})>, <DataTrace#139645385357568(#139645385357408, mask, {'mask': <openeo_driver.dry_run.DryRunDataCube object at 0x7f01d034ef70>})>])>\"},\n",
       " {'id': '[1740074236146, 533599]',\n",
       "  'time': '2025-02-20T17:57:16.146Z',\n",
       "  'level': 'info',\n",
       "  'message': 'input asset hrefs: {}'},\n",
       " {'id': '[1740074236151, 299562]',\n",
       "  'time': '2025-02-20T17:57:16.151Z',\n",
       "  'level': 'info',\n",
       "  'message': 'output asset hrefs: {}'},\n",
       " {'id': '[1740074236262, 301907]',\n",
       "  'time': '2025-02-20T17:57:16.262Z',\n",
       "  'level': 'info',\n",
       "  'message': 'wrote metadata to /batch_jobs/j-250220175546475684630774e1358c51/job_metadata.json'},\n",
       " {'id': '[1740074236318, 589765]',\n",
       "  'time': '2025-02-20T17:57:16.318Z',\n",
       "  'level': 'info',\n",
       "  'message': \"save_result format NETCDF with bounds Extent(xmin=13.84, ymin=51.7, xmax=14.3, ymax=52.05) and options {'batch_mode': True, 'file_metadata': {'title': '', 'description': '', 'institution': 'openEO platform - Geotrellis backend: 0.60.1a1'}}\"},\n",
       " {'id': '[1740074236459, 950919]',\n",
       "  'time': '2025-02-20T17:57:16.459Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 17 - partitionBy at /opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py:143. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074237620, 686331]',\n",
       "  'time': '2025-02-20T17:57:17.620Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting stage: 18 - RDD at ContextRDD.scala:32. \\nStages may combine multiple processes.'},\n",
       " {'id': '[1740074239097, 731755]',\n",
       "  'time': '2025-02-20T17:57:19.097Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7f20d5b520d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074239406, 824764]',\n",
       "  'time': '2025-02-20T17:57:19.406Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577957541006].'},\n",
       " {'id': '[1740074239407, 1215]',\n",
       "  'time': '2025-02-20T17:57:19.407Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074239407, 348285]',\n",
       "  'time': '2025-02-20T17:57:19.407Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074243340, 315313]',\n",
       "  'time': '2025-02-20T17:57:23.340Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7fca7ddaa0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074243491, 714624]',\n",
       "  'time': '2025-02-20T17:57:23.491Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578302916987].'},\n",
       " {'id': '[1740074243492, 355880]',\n",
       "  'time': '2025-02-20T17:57:23.492Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074243492, 624884]',\n",
       "  'time': '2025-02-20T17:57:23.492Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074244163, 224587]',\n",
       "  'time': '2025-02-20T17:57:24.163Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7ff31c05c0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074244642, 292651]',\n",
       "  'time': '2025-02-20T17:57:24.642Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074244642, 984183]',\n",
       "  'time': '2025-02-20T17:57:24.642Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577903007981].'},\n",
       " {'id': '[1740074244643, 836771]',\n",
       "  'time': '2025-02-20T17:57:24.643Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074246009, 348549]',\n",
       "  'time': '2025-02-20T17:57:26.009Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\"},\n",
       " {'id': '[1740074246061, 785480]',\n",
       "  'time': '2025-02-20T17:57:26.061Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Lost task 0.0 in stage 18.0 (TID 124) (10.42.247.49 executor 2): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n'},\n",
       " {'id': '[1740074246068, 903776]',\n",
       "  'time': '2025-02-20T17:57:26.068Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@773bf61f,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@5e0969b3),Vector(AccumulableInfo(458,None,Some(8366),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(0),None,false,true,None), AccumulableInfo(468,None,Some(1),None,false,true,None), AccumulableInfo(469,None,Some(0),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(379),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(0),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 8366), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 0), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 1), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 0), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 379), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 0), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(519433024, 109109976, 32768, 0, 111250, 0, 144018, 0, 8466456, 0, 8568983552, 1279995904, 2553823232, 1838415872, 0, 0, 1, 23, 3, 209, 232))'},\n",
       " {'id': '[1740074246115, 8398]',\n",
       "  'time': '2025-02-20T17:57:26.115Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7f3ec140a0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074246244, 113792]',\n",
       "  'time': '2025-02-20T17:57:26.244Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/05/S3B_SL_2_LST____20200105T204856_20200105T205156_20200822T062510_0179_034_100_0720_LR1_R_NT_004.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074246244, 350560]',\n",
       "  'time': '2025-02-20T17:57:26.244Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578257336187].'},\n",
       " {'id': '[1740074246244, 607388]',\n",
       "  'time': '2025-02-20T17:57:26.244Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074246645, 46123]',\n",
       "  'time': '2025-02-20T17:57:26.645Z',\n",
       "  'level': 'info',\n",
       "  'message': 'bbox_original=[nan, nan, nan, nan] source_coordinates=array([[14.967985, 50.913097],\\n       [14.956885, 50.907986],\\n       [14.899737, 50.907303],\\n       ...,\\n       [13.869297, 52.042343],\\n       [13.848849, 52.04699 ],\\n       [13.845058, 52.039783]], dtype=float32)'},\n",
       " {'id': '[1740074246645, 817184]',\n",
       "  'time': '2025-02-20T17:57:26.645Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/05/S3B_SL_2_LST____20200105T204856_20200105T205156_20200822T062510_0179_034_100_0720_LR1_R_NT_004.SEN3/geodetic_tx.nc'},\n",
       " {'id': '[1740074246807, 165617]',\n",
       "  'time': '2025-02-20T17:57:26.807Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Reprojecting SL_2_LST___'},\n",
       " {'id': '[1740074246807, 798929]',\n",
       "  'time': '2025-02-20T17:57:26.807Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Creating LUT with shape (129, 129, 2)'},\n",
       " {'id': '[1740074246817, 611159]',\n",
       "  'time': '2025-02-20T17:57:26.817Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Creating LUT with shape (250, 249, 2)'},\n",
       " {'id': '[1740074246836, 718775]',\n",
       "  'time': '2025-02-20T17:57:26.836Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Reprojecting LST_in:LST'},\n",
       " {'id': '[1740074246836, 945748]',\n",
       "  'time': '2025-02-20T17:57:26.836Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading LST from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/05/S3B_SL_2_LST____20200105T204856_20200105T205156_20200822T062510_0179_034_100_0720_LR1_R_NT_004.SEN3/LST_in.nc'},\n",
       " {'id': '[1740074247088, 202268]',\n",
       "  'time': '2025-02-20T17:57:27.088Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Split (1, 129, 129) in tiles of 128'},\n",
       " {'id': '[1740074247088, 239531]',\n",
       "  'time': '2025-02-20T17:57:27.088Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Done reprojecting SL_2_LST___'},\n",
       " {'id': '[1740074247088, 342367]',\n",
       "  'time': '2025-02-20T17:57:27.088Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout extent split in 1 tiles'},\n",
       " {'id': '[1740074247088, 693588]',\n",
       "  'time': '2025-02-20T17:57:27.088Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Create Tile for key SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 1, 5, 20, 48)) from (1, 128, 128)'},\n",
       " {'id': '[1740074247397, 750566]',\n",
       "  'time': '2025-02-20T17:57:27.397Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7f20d5b4d0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074247467, 12614]',\n",
       "  'time': '2025-02-20T17:57:27.467Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074247467, 96002]',\n",
       "  'time': '2025-02-20T17:57:27.467Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578301190651].'},\n",
       " {'id': '[1740074247468, 870778]',\n",
       "  'time': '2025-02-20T17:57:27.468Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3B_SL_2_LST____20200106T085951_20200106T090251_20200822T063325_0179_034_107_2160_LR1_R_NT_004.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074247742, 304806]',\n",
       "  'time': '2025-02-20T17:57:27.742Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"},\n",
       " {'id': '[1740074247804, 520007]',\n",
       "  'time': '2025-02-20T17:57:27.804Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Lost task 2.0 in stage 18.0 (TID 126) (10.42.243.240 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n'},\n",
       " {'id': '[1740074247812, 328703]',\n",
       "  'time': '2025-02-20T17:57:27.812Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@5a35f2a6,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@1f18ccc6),Vector(AccumulableInfo(458,None,Some(6358),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(380),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(25),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(27),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 6358), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 380), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 25), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 27), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(353200280, 107880248, 32768, 0, 25829, 0, 58597, 0, 8472245, 0, 8546746368, 1311604736, 703438848, 175988736, 0, 0, 1, 28, 3, 222, 250))'},\n",
       " {'id': '[1740074247859, 226803]',\n",
       "  'time': '2025-02-20T17:57:27.859Z',\n",
       "  'level': 'info',\n",
       "  'message': 'bbox_original=[nan, nan, nan, nan] source_coordinates=array([[14.918253, 52.042156],\\n       [14.942972, 52.046215],\\n       [14.955179, 52.047615],\\n       ...,\\n       [13.874681, 50.91082 ],\\n       [13.899852, 50.91349 ],\\n       [13.850042, 50.908043]], dtype=float32)'},\n",
       " {'id': '[1740074247860, 984572]',\n",
       "  'time': '2025-02-20T17:57:27.860Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3B_SL_2_LST____20200106T085951_20200106T090251_20200822T063325_0179_034_107_2160_LR1_R_NT_004.SEN3/geodetic_tx.nc'},\n",
       " {'id': '[1740074248052, 426935]',\n",
       "  'time': '2025-02-20T17:57:28.052Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Creating LUT with shape (129, 129, 2)'},\n",
       " {'id': '[1740074248052, 484105]',\n",
       "  'time': '2025-02-20T17:57:28.052Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Reprojecting SL_2_LST___'},\n",
       " {'id': '[1740074248069, 85175]',\n",
       "  'time': '2025-02-20T17:57:28.069Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Creating LUT with shape (250, 249, 2)'},\n",
       " {'id': '[1740074248108, 46702]',\n",
       "  'time': '2025-02-20T17:57:28.108Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Reprojecting LST_in:LST'},\n",
       " {'id': '[1740074248108, 83202]',\n",
       "  'time': '2025-02-20T17:57:28.108Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading LST from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3B_SL_2_LST____20200106T085951_20200106T090251_20200822T063325_0179_034_107_2160_LR1_R_NT_004.SEN3/LST_in.nc'},\n",
       " {'id': '[1740074248564, 698982]',\n",
       "  'time': '2025-02-20T17:57:28.564Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Done reprojecting SL_2_LST___'},\n",
       " {'id': '[1740074248566, 41598]',\n",
       "  'time': '2025-02-20T17:57:28.566Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Split (1, 129, 129) in tiles of 128'},\n",
       " {'id': '[1740074248566, 110590]',\n",
       "  'time': '2025-02-20T17:57:28.566Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Create Tile for key SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 1, 6, 8, 59)) from (1, 128, 128)'},\n",
       " {'id': '[1740074248566, 363570]',\n",
       "  'time': '2025-02-20T17:57:28.566Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout extent split in 1 tiles'},\n",
       " {'id': '[1740074248803, 793107]',\n",
       "  'time': '2025-02-20T17:57:28.803Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578302916987].'},\n",
       " {'id': '[1740074248804, 805991]',\n",
       "  'time': '2025-02-20T17:57:28.804Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074248804, 995636]',\n",
       "  'time': '2025-02-20T17:57:28.804Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074248988, 655092]',\n",
       "  'time': '2025-02-20T17:57:28.988Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"},\n",
       " {'id': '[1740074249029, 836120]',\n",
       "  'time': '2025-02-20T17:57:29.029Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Lost task 1.0 in stage 18.0 (TID 125) (10.42.231.60 executor 3): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n'},\n",
       " {'id': '[1740074249033, 255690]',\n",
       "  'time': '2025-02-20T17:57:29.033Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@373b5a34,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@226ae991),Vector(AccumulableInfo(458,None,Some(7605),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(375),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(42),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 7605), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 375), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 42), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(347631296, 89424440, 32768, 0, 25829, 0, 58597, 0, 4247018, 0, 8101117952, 720412672, 2005319680, 954257408, 0, 0, 0, 0, 3, 246, 246))'},\n",
       " {'id': '[1740074249502, 854227]',\n",
       "  'time': '2025-02-20T17:57:29.502Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074249502, 885484]',\n",
       "  'time': '2025-02-20T17:57:29.502Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577903007981].'},\n",
       " {'id': '[1740074249503, 168769]',\n",
       "  'time': '2025-02-20T17:57:29.503Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074251054, 336267]',\n",
       "  'time': '2025-02-20T17:57:31.054Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7ff31c05c0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074251126, 361884]',\n",
       "  'time': '2025-02-20T17:57:31.126Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074251126, 408808]',\n",
       "  'time': '2025-02-20T17:57:31.126Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577957541006].'},\n",
       " {'id': '[1740074251127, 396216]',\n",
       "  'time': '2025-02-20T17:57:31.127Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074251616, 832805]',\n",
       "  'time': '2025-02-20T17:57:31.616Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7fca7dda60d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074251695, 86405]',\n",
       "  'time': '2025-02-20T17:57:31.695Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074251695, 369951]',\n",
       "  'time': '2025-02-20T17:57:31.695Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578597447268].'},\n",
       " {'id': '[1740074251696, 366003]',\n",
       "  'time': '2025-02-20T17:57:31.696Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074252995, 989010]',\n",
       "  'time': '2025-02-20T17:57:32.995Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"},\n",
       " {'id': '[1740074253018, 443047]',\n",
       "  'time': '2025-02-20T17:57:33.018Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Lost task 2.1 in stage 18.0 (TID 129) (10.42.247.49 executor 2): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n'},\n",
       " {'id': '[1740074253026, 127878]',\n",
       "  'time': '2025-02-20T17:57:33.026Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@573f8fb8,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@e181765),Vector(AccumulableInfo(458,None,Some(4234),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(0),None,false,true,None), AccumulableInfo(468,None,Some(1),None,false,true,None), AccumulableInfo(469,None,Some(0),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(380),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(0),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 4234), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 0), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 1), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 0), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 380), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 0), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))'},\n",
       " {'id': '[1740074253163, 854369]',\n",
       "  'time': '2025-02-20T17:57:33.163Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"},\n",
       " {'id': '[1740074253199, 794546]',\n",
       "  'time': '2025-02-20T17:57:33.199Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Lost task 1.1 in stage 18.0 (TID 130) (10.42.16.189 executor 4): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n'},\n",
       " {'id': '[1740074253201, 159000]',\n",
       "  'time': '2025-02-20T17:57:33.201Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@631f1668,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@164c5dfb),Vector(AccumulableInfo(458,None,Some(3777),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(375),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(3),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 3777), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 375), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 3), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))'},\n",
       " {'id': '[1740074254275, 137208]',\n",
       "  'time': '2025-02-20T17:57:34.275Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7f20d5b4d0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074254334, 556182]',\n",
       "  'time': '2025-02-20T17:57:34.334Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074254334, 978033]',\n",
       "  'time': '2025-02-20T17:57:34.334Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578426994251].'},\n",
       " {'id': '[1740074254335, 497759]',\n",
       "  'time': '2025-02-20T17:57:34.335Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/07/S3B_SL_2_LST____20200107T195634_20200107T195934_20200822T070206_0179_034_128_0720_LR1_R_NT_004.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074254689, 766557]',\n",
       "  'time': '2025-02-20T17:57:34.689Z',\n",
       "  'level': 'info',\n",
       "  'message': 'bbox_original=[nan, nan, nan, nan] source_coordinates=array([[14.979879, 50.912243],\\n       [14.979879, 50.912243],\\n       [14.963945, 50.91541 ],\\n       ...,\\n       [13.860534, 51.846485],\\n       [13.860534, 51.846485],\\n       [13.840284, 51.846394]], dtype=float32)'},\n",
       " {'id': '[1740074254690, 748477]',\n",
       "  'time': '2025-02-20T17:57:34.690Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/07/S3B_SL_2_LST____20200107T195634_20200107T195934_20200822T070206_0179_034_128_0720_LR1_R_NT_004.SEN3/geodetic_tx.nc'},\n",
       " {'id': '[1740074254831, 321693]',\n",
       "  'time': '2025-02-20T17:57:34.831Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Creating LUT with shape (129, 129, 2)'},\n",
       " {'id': '[1740074254831, 636999]',\n",
       "  'time': '2025-02-20T17:57:34.831Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Reprojecting SL_2_LST___'},\n",
       " {'id': '[1740074254840, 803299]',\n",
       "  'time': '2025-02-20T17:57:34.840Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Creating LUT with shape (250, 249, 2)'},\n",
       " {'id': '[1740074254856, 459692]',\n",
       "  'time': '2025-02-20T17:57:34.856Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Reprojecting LST_in:LST'},\n",
       " {'id': '[1740074254856, 719637]',\n",
       "  'time': '2025-02-20T17:57:34.856Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading LST from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/07/S3B_SL_2_LST____20200107T195634_20200107T195934_20200822T070206_0179_034_128_0720_LR1_R_NT_004.SEN3/LST_in.nc'},\n",
       " {'id': '[1740074255015, 32798]',\n",
       "  'time': '2025-02-20T17:57:35.015Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout extent split in 1 tiles'},\n",
       " {'id': '[1740074255015, 49723]',\n",
       "  'time': '2025-02-20T17:57:35.015Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Done reprojecting SL_2_LST___'},\n",
       " {'id': '[1740074255015, 383355]',\n",
       "  'time': '2025-02-20T17:57:35.015Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Create Tile for key SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 1, 7, 19, 56)) from (1, 128, 128)'},\n",
       " {'id': '[1740074255015, 459389]',\n",
       "  'time': '2025-02-20T17:57:35.015Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Split (1, 129, 129) in tiles of 128'},\n",
       " {'id': '[1740074255133, 814865]',\n",
       "  'time': '2025-02-20T17:57:35.133Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577903007981].'},\n",
       " {'id': '[1740074255133, 816081]',\n",
       "  'time': '2025-02-20T17:57:35.133Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074255133, 857280]',\n",
       "  'time': '2025-02-20T17:57:35.133Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074255380, 717416]',\n",
       "  'time': '2025-02-20T17:57:35.380Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\"},\n",
       " {'id': '[1740074255416, 343988]',\n",
       "  'time': '2025-02-20T17:57:35.416Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@3d2552c5,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@73c8c93b),Vector(AccumulableInfo(458,None,Some(5995),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(379),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(5),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 5995), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 379), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 5), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))'},\n",
       " {'id': '[1740074255950, 247261]',\n",
       "  'time': '2025-02-20T17:57:35.950Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\"},\n",
       " {'id': '[1740074255963, 606523]',\n",
       "  'time': '2025-02-20T17:57:35.963Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Lost task 5.0 in stage 18.0 (TID 132) (10.42.243.240 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n'},\n",
       " {'id': '[1740074255981, 29591]',\n",
       "  'time': '2025-02-20T17:57:35.981Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@68ff3d7c,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@1c28061d),Vector(AccumulableInfo(458,None,Some(6565),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(381),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(3),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 6565), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 381), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 3), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(410118112, 108423984, 32768, 0, 25829, 0, 58597, 0, 8474696, 0, 8546885632, 1312264192, 1179045888, 388788224, 0, 0, 1, 28, 3, 222, 250))'},\n",
       " {'id': '[1740074257836, 554303]',\n",
       "  'time': '2025-02-20T17:57:37.836Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7f3ec140a0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074257915, 740985]',\n",
       "  'time': '2025-02-20T17:57:37.915Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578993668796].'},\n",
       " {'id': '[1740074257916, 106211]',\n",
       "  'time': '2025-02-20T17:57:37.916Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074257916, 419843]',\n",
       "  'time': '2025-02-20T17:57:37.916Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074258122, 675596]',\n",
       "  'time': '2025-02-20T17:57:38.122Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7ff31c05c0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074258166, 808051]',\n",
       "  'time': '2025-02-20T17:57:38.166Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7fca7dda50d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074258189, 248331]',\n",
       "  'time': '2025-02-20T17:57:38.189Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578302916987].'},\n",
       " {'id': '[1740074258189, 965368]',\n",
       "  'time': '2025-02-20T17:57:38.189Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074258190, 925420]',\n",
       "  'time': '2025-02-20T17:57:38.190Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074258241, 862918]',\n",
       "  'time': '2025-02-20T17:57:38.241Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1579078497939].'},\n",
       " {'id': '[1740074258242, 802707]',\n",
       "  'time': '2025-02-20T17:57:38.242Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074258242, 970652]',\n",
       "  'time': '2025-02-20T17:57:38.242Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/15/S3A_SL_2_LST____20200115T085458_20200115T103557_20200116T153245_6059_053_378______LN2_O_NT_004.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074258494, 265867]',\n",
       "  'time': '2025-02-20T17:57:38.494Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"},\n",
       " {'id': '[1740074258506, 959198]',\n",
       "  'time': '2025-02-20T17:57:38.506Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@b8cdc27,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@3e385d7c),Vector(AccumulableInfo(458,None,Some(3461),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(0),None,false,true,None), AccumulableInfo(468,None,Some(1),None,false,true,None), AccumulableInfo(469,None,Some(0),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(375),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(0),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 3461), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 0), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 1), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 0), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 375), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 0), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))'},\n",
       " {'id': '[1740074259522, 178864]',\n",
       "  'time': '2025-02-20T17:57:39.522Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7f3b280870d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074259562, 413503]',\n",
       "  'time': '2025-02-20T17:57:39.562Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7f655360b0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074259670, 386280]',\n",
       "  'time': '2025-02-20T17:57:39.670Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7efe104550d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074259693, 31706]',\n",
       "  'time': '2025-02-20T17:57:39.693Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7f20d5b4d0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074259816, 67125]',\n",
       "  'time': '2025-02-20T17:57:39.816Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1580724230572].'},\n",
       " {'id': '[1740074259816, 944665]',\n",
       "  'time': '2025-02-20T17:57:39.816Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074259817, 659456]',\n",
       "  'time': '2025-02-20T17:57:39.817Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/03/S3B_SL_2_LST____20200203T100351_20200203T114450_20200204T175415_6059_035_122______LN2_O_NT_004.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074259819, 105317]',\n",
       "  'time': '2025-02-20T17:57:39.819Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074259819, 194692]',\n",
       "  'time': '2025-02-20T17:57:39.819Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074259819, 537512]',\n",
       "  'time': '2025-02-20T17:57:39.819Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577957541006].'},\n",
       " {'id': '[1740074259828, 240976]',\n",
       "  'time': '2025-02-20T17:57:39.828Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578514195022].'},\n",
       " {'id': '[1740074259828, 467333]',\n",
       "  'time': '2025-02-20T17:57:39.828Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/08/S3A_SL_2_LST____20200108T200955_20200108T201255_20210121T145509_0179_053_285_0720_LR1_R_NT_004.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074259828, 576836]',\n",
       "  'time': '2025-02-20T17:57:39.828Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074259931, 131222]',\n",
       "  'time': '2025-02-20T17:57:39.931Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578597447268].'},\n",
       " {'id': '[1740074259931, 299582]',\n",
       "  'time': '2025-02-20T17:57:39.931Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074259932, 489714]',\n",
       "  'time': '2025-02-20T17:57:39.932Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074260259, 761176]',\n",
       "  'time': '2025-02-20T17:57:40.259Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/08/S3A_SL_2_LST____20200108T200955_20200108T201255_20210121T145509_0179_053_285_0720_LR1_R_NT_004.SEN3/geodetic_tx.nc'},\n",
       " {'id': '[1740074260259, 773705]',\n",
       "  'time': '2025-02-20T17:57:40.259Z',\n",
       "  'level': 'info',\n",
       "  'message': 'bbox_original=[nan, nan, nan, nan] source_coordinates=array([[14.980168, 50.91207 ],\\n       [14.966739, 50.908527],\\n       [14.97621 , 50.921303],\\n       ...,\\n       [13.853938, 52.04209 ],\\n       [13.840382, 52.038013],\\n       [13.84907 , 52.04998 ]], dtype=float32)'},\n",
       " {'id': '[1740074260407, 22658]',\n",
       "  'time': '2025-02-20T17:57:40.407Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Creating LUT with shape (129, 129, 2)'},\n",
       " {'id': '[1740074260407, 508743]',\n",
       "  'time': '2025-02-20T17:57:40.407Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Reprojecting SL_2_LST___'},\n",
       " {'id': '[1740074260416, 2953]',\n",
       "  'time': '2025-02-20T17:57:40.416Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Creating LUT with shape (250, 249, 2)'},\n",
       " {'id': '[1740074260433, 366942]',\n",
       "  'time': '2025-02-20T17:57:40.433Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Reprojecting LST_in:LST'},\n",
       " {'id': '[1740074260433, 510477]',\n",
       "  'time': '2025-02-20T17:57:40.433Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading LST from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/08/S3A_SL_2_LST____20200108T200955_20200108T201255_20210121T145509_0179_053_285_0720_LR1_R_NT_004.SEN3/LST_in.nc'},\n",
       " {'id': '[1740074260655, 23243]',\n",
       "  'time': '2025-02-20T17:57:40.655Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Split (1, 129, 129) in tiles of 128'},\n",
       " {'id': '[1740074260655, 24373]',\n",
       "  'time': '2025-02-20T17:57:40.655Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Create Tile for key SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 1, 8, 20, 9)) from (1, 128, 128)'},\n",
       " {'id': '[1740074260655, 693006]',\n",
       "  'time': '2025-02-20T17:57:40.655Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Done reprojecting SL_2_LST___'},\n",
       " {'id': '[1740074260655, 832483]',\n",
       "  'time': '2025-02-20T17:57:40.655Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout extent split in 1 tiles'},\n",
       " {'id': '[1740074261780, 537651]',\n",
       "  'time': '2025-02-20T17:57:41.780Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\"},\n",
       " {'id': '[1740074261791, 397955]',\n",
       "  'time': '2025-02-20T17:57:41.791Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Lost task 8.0 in stage 18.0 (TID 139) (10.42.16.189 executor 4): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n'},\n",
       " {'id': '[1740074261793, 150681]',\n",
       "  'time': '2025-02-20T17:57:41.793Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@2f3d831a,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@73f9600e),Vector(AccumulableInfo(458,None,Some(5399),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(380),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(2),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 5399), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 380), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 2), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(281273632, 87342960, 32768, 0, 25829, 0, 58597, 0, 4263247, 0, 6465241088, 717463552, 2014699520, 990191616, 0, 0, 0, 0, 3, 215, 215))'},\n",
       " {'id': '[1740074261906, 669244]',\n",
       "  'time': '2025-02-20T17:57:41.906Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074261906, 879443]',\n",
       "  'time': '2025-02-20T17:57:41.906Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578993668796].'},\n",
       " {'id': '[1740074261907, 3059]',\n",
       "  'time': '2025-02-20T17:57:41.907Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074262202, 168131]',\n",
       "  'time': '2025-02-20T17:57:42.202Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"},\n",
       " {'id': '[1740074262216, 402921]',\n",
       "  'time': '2025-02-20T17:57:42.216Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Lost task 2.2 in stage 18.0 (TID 137) (10.42.231.60 executor 3): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n'},\n",
       " {'id': '[1740074262219, 59095]',\n",
       "  'time': '2025-02-20T17:57:42.219Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@1e79e7b2,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@62d69abc),Vector(AccumulableInfo(458,None,Some(5822),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(380),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(3),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 5822), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 380), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 3), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(427629528, 90979936, 32768, 0, 25829, 0, 58597, 0, 4271663, 0, 8238493696, 797495296, 366895104, 86925312, 0, 0, 0, 0, 3, 246, 246))'},\n",
       " {'id': '[1740074262726, 501320]',\n",
       "  'time': '2025-02-20T17:57:42.726Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/15/S3A_SL_2_LST____20200115T085458_20200115T103557_20200116T153245_6059_053_378______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"},\n",
       " {'id': '[1740074262747, 875771]',\n",
       "  'time': '2025-02-20T17:57:42.747Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Lost task 9.0 in stage 18.0 (TID 140) (10.42.243.240 executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/15/S3A_SL_2_LST____20200115T085458_20200115T103557_20200116T153245_6059_053_378______LN2_O_NT_004.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n'},\n",
       " {'id': '[1740074262757, 388524]',\n",
       "  'time': '2025-02-20T17:57:42.757Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/15/S3A_SL_2_LST____20200115T085458_20200115T103557_20200116T153245_6059_053_378______LN2_O_NT_004.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@21b0f0af,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/15/S3A_SL_2_LST____20200115T085458_20200115T103557_20200116T153245_6059_053_378______LN2_O_NT_004.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@19f10d87),Vector(AccumulableInfo(458,None,Some(6346),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(380),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(10),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 6346), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 380), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 10), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(474706632, 108645096, 32768, 0, 25829, 0, 58597, 0, 8475290, 0, 8548982784, 1313402880, 2500182016, 1787789312, 0, 0, 1, 28, 3, 222, 250))'},\n",
       " {'id': '[1740074263145, 467017]',\n",
       "  'time': '2025-02-20T17:57:43.145Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7f3ec140a0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074263147, 223643]',\n",
       "  'time': '2025-02-20T17:57:43.147Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577903007981].'},\n",
       " {'id': '[1740074263147, 653057]',\n",
       "  'time': '2025-02-20T17:57:43.147Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074263147, 677660]',\n",
       "  'time': '2025-02-20T17:57:43.147Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074263181, 839332]',\n",
       "  'time': '2025-02-20T17:57:43.181Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\"},\n",
       " {'id': '[1740074263222, 238157]',\n",
       "  'time': '2025-02-20T17:57:43.222Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@48e43d7c,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@1eb14da6),Vector(AccumulableInfo(458,None,Some(6766),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(461,None,Some(66),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(381),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(11),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 6766), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 461, name: Some(internal.metrics.jvmGCTime), value: 66), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 381), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 11), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))'},\n",
       " {'id': '[1740074263433, 270387]',\n",
       "  'time': '2025-02-20T17:57:43.433Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\"},\n",
       " {'id': '[1740074263470, 472908]',\n",
       "  'time': '2025-02-20T17:57:43.470Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Lost task 0.2 in stage 18.0 (TID 136) (10.42.90.120 executor 7): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n'},\n",
       " {'id': '[1740074263472, 106418]',\n",
       "  'time': '2025-02-20T17:57:43.472Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@38a2f357,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40396, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@29ae5cf1),Vector(AccumulableInfo(458,None,Some(7009),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(461,None,Some(63),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(379),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(12),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 7009), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 461, name: Some(internal.metrics.jvmGCTime), value: 63), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 379), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 12), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))'},\n",
       " {'id': '[1740074263794, 508451]',\n",
       "  'time': '2025-02-20T17:57:43.794Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7ff8ebb8d0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074263898, 206794]',\n",
       "  'time': '2025-02-20T17:57:43.898Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7ff31c05c0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074264054, 440903]',\n",
       "  'time': '2025-02-20T17:57:44.054Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1581670115362].'},\n",
       " {'id': '[1740074264054, 831813]',\n",
       "  'time': '2025-02-20T17:57:44.054Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074264055, 682564]',\n",
       "  'time': '2025-02-20T17:57:44.055Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/14/S3B_SL_2_LST____20200214T084835_20200214T085135_20200822T174230_0180_035_278_2160_LR1_R_NT_004.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074264142, 377627]',\n",
       "  'time': '2025-02-20T17:57:44.142Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1579457855543].'},\n",
       " {'id': '[1740074264143, 615278]',\n",
       "  'time': '2025-02-20T17:57:44.143Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/19/S3B_SL_2_LST____20200119T181736_20200119T195835_20200121T020758_6059_034_298______LN2_O_NT_004.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074264143, 886165]',\n",
       "  'time': '2025-02-20T17:57:44.143Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074264322, 77061]',\n",
       "  'time': '2025-02-20T17:57:44.322Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7efe104550d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074264384, 121210]',\n",
       "  'time': '2025-02-20T17:57:44.384Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1579078497939].'},\n",
       " {'id': '[1740074264384, 559097]',\n",
       "  'time': '2025-02-20T17:57:44.384Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074264384, 949493]',\n",
       "  'time': '2025-02-20T17:57:44.384Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/15/S3A_SL_2_LST____20200115T085458_20200115T103557_20200116T153245_6059_053_378______LN2_O_NT_004.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074264504, 96395]',\n",
       "  'time': '2025-02-20T17:57:44.504Z',\n",
       "  'level': 'info',\n",
       "  'message': 'bbox_original=[nan, nan, nan, nan] source_coordinates=array([[14.976556, 52.04619 ],\\n       [14.976556, 52.04619 ],\\n       [14.856339, 52.04986 ],\\n       ...,\\n       [14.204908, 50.908207],\\n       [14.219062, 50.907364],\\n       [14.062057, 50.907753]], dtype=float32)'},\n",
       " {'id': '[1740074264504, 594671]',\n",
       "  'time': '2025-02-20T17:57:44.504Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/14/S3B_SL_2_LST____20200214T084835_20200214T085135_20200822T174230_0180_035_278_2160_LR1_R_NT_004.SEN3/geodetic_tx.nc'},\n",
       " {'id': '[1740074264520, 149068]',\n",
       "  'time': '2025-02-20T17:57:44.520Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/03/S3B_SL_2_LST____20200203T100351_20200203T114450_20200204T175415_6059_035_122______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\"},\n",
       " {'id': '[1740074264538, 599985]',\n",
       "  'time': '2025-02-20T17:57:44.538Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Lost task 11.0 in stage 18.0 (TID 142) (10.42.247.49 executor 2): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/03/S3B_SL_2_LST____20200203T100351_20200203T114450_20200204T175415_6059_035_122______LN2_O_NT_004.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n'},\n",
       " {'id': '[1740074264547, 27862]',\n",
       "  'time': '2025-02-20T17:57:44.547Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/03/S3B_SL_2_LST____20200203T100351_20200203T114450_20200204T175415_6059_035_122______LN2_O_NT_004.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@40c89b65,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/03/S3B_SL_2_LST____20200203T100351_20200203T114450_20200204T175415_6059_035_122______LN2_O_NT_004.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40393, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@548022a7),Vector(AccumulableInfo(458,None,Some(6020),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(461,None,Some(17),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(0),None,false,true,None), AccumulableInfo(468,None,Some(1),None,false,true,None), AccumulableInfo(469,None,Some(0),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(379),None,false,true,None), AccumulableInfo(472,None,Some(0),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(0),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 6020), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 461, name: Some(internal.metrics.jvmGCTime), value: 17), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 0), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 1), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 0), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 379), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 0), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))'},\n",
       " {'id': '[1740074264639, 132209]',\n",
       "  'time': '2025-02-20T17:57:44.639Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Reprojecting SL_2_LST___'},\n",
       " {'id': '[1740074264640, 304015]',\n",
       "  'time': '2025-02-20T17:57:44.640Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Creating LUT with shape (129, 129, 2)'},\n",
       " {'id': '[1740074264650, 57681]',\n",
       "  'time': '2025-02-20T17:57:44.650Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Creating LUT with shape (250, 249, 2)'},\n",
       " {'id': '[1740074264671, 828596]',\n",
       "  'time': '2025-02-20T17:57:44.671Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7fca7dda50d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074264674, 273028]',\n",
       "  'time': '2025-02-20T17:57:44.674Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading LST from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/02/14/S3B_SL_2_LST____20200214T084835_20200214T085135_20200822T174230_0180_035_278_2160_LR1_R_NT_004.SEN3/LST_in.nc'},\n",
       " {'id': '[1740074264674, 658129]',\n",
       "  'time': '2025-02-20T17:57:44.674Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Reprojecting LST_in:LST'},\n",
       " {'id': '[1740074264675, 102355]',\n",
       "  'time': '2025-02-20T17:57:44.675Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578302916987].'},\n",
       " {'id': '[1740074264675, 234527]',\n",
       "  'time': '2025-02-20T17:57:44.675Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074264676, 551937]',\n",
       "  'time': '2025-02-20T17:57:44.676Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/06/S3A_SL_2_LST____20200106T092837_20200106T110936_20200107T155436_6059_053_250______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074264744, 80845]',\n",
       "  'time': '2025-02-20T17:57:44.744Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7f3b280870d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074264822, 48332]',\n",
       "  'time': '2025-02-20T17:57:44.822Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/09/S3B_SL_2_LST____20200109T191727_20200109T205826_20200111T012239_6059_034_156______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074264822, 83897]',\n",
       "  'time': '2025-02-20T17:57:44.822Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074264822, 230150]',\n",
       "  'time': '2025-02-20T17:57:44.822Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1578597447268].'},\n",
       " {'id': '[1740074264873, 64740]',\n",
       "  'time': '2025-02-20T17:57:44.873Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout extent split in 1 tiles'},\n",
       " {'id': '[1740074264873, 469027]',\n",
       "  'time': '2025-02-20T17:57:44.873Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Done reprojecting SL_2_LST___'},\n",
       " {'id': '[1740074264873, 724448]',\n",
       "  'time': '2025-02-20T17:57:44.873Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Create Tile for key SpaceTimeKey(col=0, row=0, instant=datetime.datetime(2020, 2, 14, 8, 48)) from (1, 128, 128)'},\n",
       " {'id': '[1740074264873, 750291]',\n",
       "  'time': '2025-02-20T17:57:44.873Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Split (1, 129, 129) in tiles of 128'},\n",
       " {'id': '[1740074264879, 131876]',\n",
       "  'time': '2025-02-20T17:57:44.879Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\"},\n",
       " {'id': '[1740074264919, 429559]',\n",
       "  'time': '2025-02-20T17:57:44.919Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Lost task 8.1 in stage 18.0 (TID 144) (10.42.146.92 executor 6): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n'},\n",
       " {'id': '[1740074264937, 400057]',\n",
       "  'time': '2025-02-20T17:57:44.937Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@7b975b2b,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/14/S3A_SL_2_LST____20200114T092109_20200114T110208_20200115T201243_6059_053_364______LN2_O_NT_004.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40395, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@2005c97c),Vector(AccumulableInfo(458,None,Some(3088),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(380),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(9),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(15),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 3088), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 380), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 9), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 15), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))'},\n",
       " {'id': '[1740074266041, 223917]',\n",
       "  'time': '2025-02-20T17:57:46.041Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Overriding sys.excepthook with <function _sys_excepthook at 0x7f20d5b4d0d0> (was <built-in function excepthook>)'},\n",
       " {'id': '[1740074266042, 263614]',\n",
       "  'time': '2025-02-20T17:57:46.042Z',\n",
       "  'level': 'info',\n",
       "  'message': ' Layout key extent: col[0:0] row[0:0] (1x1=1 tiles) instant[1577957541006].'},\n",
       " {'id': '[1740074266042, 820846]',\n",
       "  'time': '2025-02-20T17:57:46.042Z',\n",
       "  'level': 'info',\n",
       "  'message': \" Layout extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05} EPSG 4326:\"},\n",
       " {'id': '[1740074266043, 108079]',\n",
       "  'time': '2025-02-20T17:57:46.043Z',\n",
       "  'level': 'debug',\n",
       "  'message': 'Reading lat/lon from file /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/02/S3A_SL_2_LST____20200102T093221_20200102T111320_20200103T164256_6059_053_193______LN2_O_NT_003.SEN3/geodetic_in.nc'},\n",
       " {'id': '[1740074266317, 137870]',\n",
       "  'time': '2025-02-20T17:57:46.317Z',\n",
       "  'level': 'error',\n",
       "  'message': \"Failed to read Sentinel-3 SL_2_LST___ ['LST_in:LST'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {'xmin': 13.84, 'xmax': 14.982857142857087, 'ymin': 50.90714285714291, 'ymax': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\"},\n",
       " {'id': '[1740074266338, 921628]',\n",
       "  'time': '2025-02-20T17:57:46.338Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Lost task 1.3 in stage 18.0 (TID 143) (10.42.16.189 executor 4): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n'},\n",
       " {'id': '[1740074266340, 929416]',\n",
       "  'time': '2025-02-20T17:57:46.340Z',\n",
       "  'level': 'error',\n",
       "  'message': 'Task 1 in stage 18.0 failed 4 times; aborting job'},\n",
       " {'id': '[1740074266353, 858226]',\n",
       "  'time': '2025-02-20T17:57:46.353Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'Task error: ExceptionFailure(org.apache.spark.api.python.PythonException,Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n,[Ljava.lang.StackTraceElement;@24927daa,org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n,Some(org.apache.spark.ThrowableSerializationWrapper@7152f685),Vector(AccumulableInfo(458,None,Some(4516),None,false,true,None), AccumulableInfo(460,None,Some(0),None,false,true,None), AccumulableInfo(465,None,Some(32768),None,false,true,None), AccumulableInfo(467,None,Some(1),None,false,true,None), AccumulableInfo(468,None,Some(0),None,false,true,None), AccumulableInfo(469,None,Some(375),None,false,true,None), AccumulableInfo(470,None,Some(0),None,false,true,None), AccumulableInfo(471,None,Some(0),None,false,true,None), AccumulableInfo(472,None,Some(19),None,false,true,None), AccumulableInfo(473,None,Some(1),None,false,true,None), AccumulableInfo(474,None,Some(0),None,false,true,None), AccumulableInfo(475,None,Some(0),None,false,true,None), AccumulableInfo(476,None,Some(0),None,false,true,None), AccumulableInfo(477,None,Some(0),None,false,true,None), AccumulableInfo(478,None,Some(0),None,false,true,None), AccumulableInfo(479,None,Some(0),None,false,true,None), AccumulableInfo(480,None,Some(0),None,false,true,None), AccumulableInfo(481,None,Some(0),None,false,true,None), AccumulableInfo(482,None,Some(24),None,false,true,None), AccumulableInfo(483,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 458, name: Some(internal.metrics.executorRunTime), value: 4516), LongAccumulator(id: 460, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 465, name: Some(internal.metrics.peakExecutionMemory), value: 32768), LongAccumulator(id: 467, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 1), LongAccumulator(id: 468, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 0), LongAccumulator(id: 469, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 375), LongAccumulator(id: 470, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 471, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 0), LongAccumulator(id: 472, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 19), LongAccumulator(id: 473, name: Some(internal.metrics.shuffle.read.recordsRead), value: 1), LongAccumulator(id: 474, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 475, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 476, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 477, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 478, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 479, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 480, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 481, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 482, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 24), LongAccumulator(id: 483, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))'},\n",
       " {'id': '[1740074266376, 404048]',\n",
       "  'time': '2025-02-20T17:57:46.376Z',\n",
       "  'level': 'error',\n",
       "  'message': 'Stage error: Job aborted due to stage failure: Task 1 in stage 18.0 failed 4 times, most recent failure: Lost task 1.3 in stage 18.0 (TID 143) (10.42.16.189 executor 4): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\\nDriver stacktrace:'},\n",
       " {'id': '[1740074266576, 899488]',\n",
       "  'time': '2025-02-20T17:57:46.576Z',\n",
       "  'level': 'info',\n",
       "  'message': 'input asset hrefs: {}'},\n",
       " {'id': '[1740074266580, 929631]',\n",
       "  'time': '2025-02-20T17:57:46.580Z',\n",
       "  'level': 'info',\n",
       "  'message': 'output asset hrefs: {}'},\n",
       " {'id': '[1740074266633, 804786]',\n",
       "  'time': '2025-02-20T17:57:46.633Z',\n",
       "  'level': 'info',\n",
       "  'message': 'wrote metadata to /batch_jobs/j-250220175546475684630774e1358c51/job_metadata.json'},\n",
       " {'id': '[1740074266851, 753431]',\n",
       "  'time': '2025-02-20T17:57:46.851Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Summary of the executed stages with the Logs of the longest stages:'},\n",
       " {'id': '[1740074266852, 460420]',\n",
       "  'time': '2025-02-20T17:57:46.852Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Total number of stages: 14'},\n",
       " {'id': '[1740074266852, 722178]',\n",
       "  'time': '2025-02-20T17:57:46.852Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Total stage runtime: 1 minutes'},\n",
       " {'id': '[1740074266852, 801728]',\n",
       "  'time': '2025-02-20T17:57:46.852Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Total executor allocation time: 232009898 minutes'},\n",
       " {'id': '[1740074266853, 677398]',\n",
       "  'time': '2025-02-20T17:57:46.853Z',\n",
       "  'level': 'warning',\n",
       "  'message': 'A part of the process graph failed, and will be retried, the reason was: \"Job aborted due to stage failure: Task 1 in stage 18.0 failed 4 times, most recent failure: Lost task 1.3 in stage 18.0 (TID 143) (10.42.16.189 executor 4): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 274, in _as_array_or_item\\n    data = np.asarray(data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 693, in __array__\\n    self._ensure_cached()\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 690, in _ensure_cached\\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 663, in __array__\\n    return np.asarray(self.array, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 218, in _scale_offset_decoding\\n    data = np.array(data, dtype=dtype, copy=True)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 70, in __array__\\n    return self.func(self.array)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/coding/variables.py\", line 138, in _apply_mask\\n    data = np.asarray(data, dtype=dtype)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 568, in __array__\\n    return np.asarray(array[self.key], dtype=None)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 72, in __getitem__\\n    return indexing.explicit_indexing_adapter(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/indexing.py\", line 853, in explicit_indexing_adapter\\n    result = raw_indexing_method(raw_key.tuple)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\", line 85, in _getitem\\n    array = getitem(original_array, key)\\n  File \"src/netCDF4/_netCDF4.pyx\", line 5079, in netCDF4._netCDF4.Variable.__getitem__\\n  File \"src/netCDF4/_netCDF4.pyx\", line 6028, in netCDF4._netCDF4.Variable._get\\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\\n    process()\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 269, in read_product\\n    raise InternalException(msg)\\nopeneo_driver.errors.InternalException: Server error: Failed to read Sentinel-3 SL_2_LST___ [\\'LST_in:LST\\'] for /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/01/01/S3A_SL_2_LST____20200101T182328_20200101T200427_20200103T005303_6059_053_184______LN2_O_NT_003.SEN3 and extent {\\'xmin\\': 13.84, \\'xmax\\': 14.982857142857087, \\'ymin\\': 50.90714285714291, \\'ymax\\': 52.05}. Error: Unable to allocate 231. MiB for an array with shape (40394, 1500) and data type int32\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\\nDriver stacktrace:\"\\nYour job may still complete if the failure was caused by a transient error, but will take more time. A common cause of transient errors is too little executor memory (overhead). Too low executor-memory can be seen by a high \\'garbage collection\\' time, which was: 0.0 seconds.\\n'},\n",
       " {'id': '[1740074268613, 252849]',\n",
       "  'time': '2025-02-20T17:57:48.613Z',\n",
       "  'level': 'info',\n",
       "  'message': 'Starting batch job os.getpid()=79: fail 2025-02-20 17:57:48.613108, elapsed 0:01:24.809122'},\n",
       " {'id': '[1740074268620, 46728]',\n",
       "  'time': '2025-02-20T17:57:48.620Z',\n",
       "  'level': 'error',\n",
       "  'message': 'OpenEO batch job failed: Exception during Spark execution: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 255, in read_product\\n    orfeo_bands = create_s3_toa(\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 332, in create_s3_toa\\n    bbox_original, source_coordinates, data_mask = _read_latlonfile(bbox_tile, geofile, lat_band, lon_band)\\n  File \"/opt/openeo/lib/python3.8/site-packages/openeogeotrellis/collections/sentinel3.py\", line 543, in _read_latlonfile\\n    lat_lon_ds = xr.open_dataset(latlon_file).astype(\"float32\")\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/common.py\", line 1433, in astype\\n    return apply_ufunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 1116, in apply_ufunc\\n    return apply_dataset_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 428, in apply_dataset_vfunc\\n    result_vars = apply_dict_of_variables_vfunc(\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 373, in apply_dict_of_variables_vfunc\\n    result_vars[name] = func(*variable_args)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 628, in apply_variable_ufunc\\n    input_data = [\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 629, in <listcomp>\\n    broadcast_compat_data(arg, broadcast_dims, core_dims)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/computation.py\", line 542, in broadcast_compat_data\\n    data = variable.data\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 361, in data\\n    return self.values\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variable.py\", line 512, in values\\n    return _as_array_or_item(self._data)\\n  File \"/opt/openeo/lib/python3.8/site-packages/xarray/core/variabl...'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.job('j-250220175546475684630774e1358c51').logs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evapo_sentinelhub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
